{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 10-3 – Introduction to Artificial Neural Networks with Keras**\n",
    "\n",
    "Homework notebook\n",
    "\n",
    "### 학번: 20201581\n",
    "\n",
    "### 이름: 김형성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:  sys.version_info(major=3, minor=9, micro=21, releaselevel='final', serial=0)\n",
      "1.2.2\n",
      "TF version:  2.10.0\n",
      "Default GPU Device: /device:GPU:0\n",
      "============\n",
      "Device Test\n",
      "============\n",
      "name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4336482417900583924\n",
      "xla_global_id: -1\n",
      "\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14211350528\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15601393363618015123\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.7 is required\n",
    "import sys\n",
    "print(\"Python: \", sys.version_info)\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "from packaging import version\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.8.0 is required\n",
    "import tensorflow as tf\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "\n",
    "# GPU check\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "# GPU check\n",
    "if not \"google.colab\" in sys.modules: \n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(\"============\")\n",
    "    print('Device Test')\n",
    "    print(\"============\")\n",
    "    print(device_lib.list_local_devices()[0])\n",
    "    print(device_lib.list_local_devices()[1])\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "# Where to save the figures\n",
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"ann\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import keras\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42, test_size=0.1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42, test_size=0.2)\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 1.7247 - dense_2_loss: 1.6730 - dense_3_loss: 2.1907 - dense_2_root_mean_squared_error: 1.2934 - dense_3_root_mean_squared_error: 1.4801 - val_loss: 0.6290 - val_dense_2_loss: 0.5992 - val_dense_3_loss: 0.8971 - val_dense_2_root_mean_squared_error: 0.7741 - val_dense_3_root_mean_squared_error: 0.9472\n",
      "Epoch 2/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.5276 - dense_2_loss: 0.5021 - dense_3_loss: 0.7566 - dense_2_root_mean_squared_error: 0.7086 - dense_3_root_mean_squared_error: 0.8698 - val_loss: 0.4771 - val_dense_2_loss: 0.4619 - val_dense_3_loss: 0.6138 - val_dense_2_root_mean_squared_error: 0.6796 - val_dense_3_root_mean_squared_error: 0.7834\n",
      "Epoch 3/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.4365 - dense_2_loss: 0.4200 - dense_3_loss: 0.5854 - dense_2_root_mean_squared_error: 0.6481 - dense_3_root_mean_squared_error: 0.7651 - val_loss: 0.4344 - val_dense_2_loss: 0.4203 - val_dense_3_loss: 0.5621 - val_dense_2_root_mean_squared_error: 0.6483 - val_dense_3_root_mean_squared_error: 0.7498\n",
      "Epoch 4/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.4081 - dense_2_loss: 0.3935 - dense_3_loss: 0.5396 - dense_2_root_mean_squared_error: 0.6273 - dense_3_root_mean_squared_error: 0.7346 - val_loss: 0.4196 - val_dense_2_loss: 0.4074 - val_dense_3_loss: 0.5294 - val_dense_2_root_mean_squared_error: 0.6383 - val_dense_3_root_mean_squared_error: 0.7276\n",
      "Epoch 5/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3903 - dense_2_loss: 0.3771 - dense_3_loss: 0.5086 - dense_2_root_mean_squared_error: 0.6141 - dense_3_root_mean_squared_error: 0.7132 - val_loss: 0.3971 - val_dense_2_loss: 0.3862 - val_dense_3_loss: 0.4952 - val_dense_2_root_mean_squared_error: 0.6215 - val_dense_3_root_mean_squared_error: 0.7037\n",
      "Epoch 6/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3830 - dense_2_loss: 0.3720 - dense_3_loss: 0.4821 - dense_2_root_mean_squared_error: 0.6099 - dense_3_root_mean_squared_error: 0.6943 - val_loss: 0.4300 - val_dense_2_loss: 0.4240 - val_dense_3_loss: 0.4845 - val_dense_2_root_mean_squared_error: 0.6511 - val_dense_3_root_mean_squared_error: 0.6961\n",
      "Epoch 7/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3751 - dense_2_loss: 0.3658 - dense_3_loss: 0.4590 - dense_2_root_mean_squared_error: 0.6048 - dense_3_root_mean_squared_error: 0.6775 - val_loss: 0.4004 - val_dense_2_loss: 0.3933 - val_dense_3_loss: 0.4652 - val_dense_2_root_mean_squared_error: 0.6271 - val_dense_3_root_mean_squared_error: 0.6821\n",
      "Epoch 8/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3881 - dense_2_loss: 0.3805 - dense_3_loss: 0.4557 - dense_2_root_mean_squared_error: 0.6169 - dense_3_root_mean_squared_error: 0.6750 - val_loss: 0.3732 - val_dense_2_loss: 0.3657 - val_dense_3_loss: 0.4405 - val_dense_2_root_mean_squared_error: 0.6047 - val_dense_3_root_mean_squared_error: 0.6637\n",
      "Epoch 9/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3587 - dense_2_loss: 0.3503 - dense_3_loss: 0.4345 - dense_2_root_mean_squared_error: 0.5918 - dense_3_root_mean_squared_error: 0.6592 - val_loss: 0.3660 - val_dense_2_loss: 0.3588 - val_dense_3_loss: 0.4306 - val_dense_2_root_mean_squared_error: 0.5990 - val_dense_3_root_mean_squared_error: 0.6562\n",
      "Epoch 10/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3489 - dense_2_loss: 0.3408 - dense_3_loss: 0.4212 - dense_2_root_mean_squared_error: 0.5838 - dense_3_root_mean_squared_error: 0.6490 - val_loss: 0.3641 - val_dense_2_loss: 0.3579 - val_dense_3_loss: 0.4196 - val_dense_2_root_mean_squared_error: 0.5983 - val_dense_3_root_mean_squared_error: 0.6478\n",
      "Epoch 11/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3434 - dense_2_loss: 0.3356 - dense_3_loss: 0.4136 - dense_2_root_mean_squared_error: 0.5793 - dense_3_root_mean_squared_error: 0.6431 - val_loss: 0.3626 - val_dense_2_loss: 0.3563 - val_dense_3_loss: 0.4190 - val_dense_2_root_mean_squared_error: 0.5969 - val_dense_3_root_mean_squared_error: 0.6473\n",
      "Epoch 12/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3589 - dense_2_loss: 0.3525 - dense_3_loss: 0.4163 - dense_2_root_mean_squared_error: 0.5937 - dense_3_root_mean_squared_error: 0.6453 - val_loss: 0.3535 - val_dense_2_loss: 0.3471 - val_dense_3_loss: 0.4117 - val_dense_2_root_mean_squared_error: 0.5891 - val_dense_3_root_mean_squared_error: 0.6417\n",
      "Epoch 13/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3438 - dense_2_loss: 0.3368 - dense_3_loss: 0.4067 - dense_2_root_mean_squared_error: 0.5803 - dense_3_root_mean_squared_error: 0.6378 - val_loss: 0.3583 - val_dense_2_loss: 0.3530 - val_dense_3_loss: 0.4057 - val_dense_2_root_mean_squared_error: 0.5942 - val_dense_3_root_mean_squared_error: 0.6369\n",
      "Epoch 14/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3487 - dense_2_loss: 0.3424 - dense_3_loss: 0.4056 - dense_2_root_mean_squared_error: 0.5851 - dense_3_root_mean_squared_error: 0.6369 - val_loss: 0.3694 - val_dense_2_loss: 0.3643 - val_dense_3_loss: 0.4156 - val_dense_2_root_mean_squared_error: 0.6036 - val_dense_3_root_mean_squared_error: 0.6446\n",
      "Epoch 15/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.4031 - dense_2_loss: 0.3994 - dense_3_loss: 0.4369 - dense_2_root_mean_squared_error: 0.6320 - dense_3_root_mean_squared_error: 0.6610 - val_loss: 0.3654 - val_dense_2_loss: 0.3608 - val_dense_3_loss: 0.4076 - val_dense_2_root_mean_squared_error: 0.6006 - val_dense_3_root_mean_squared_error: 0.6384\n",
      "Epoch 16/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3422 - dense_2_loss: 0.3362 - dense_3_loss: 0.3965 - dense_2_root_mean_squared_error: 0.5798 - dense_3_root_mean_squared_error: 0.6297 - val_loss: 0.3500 - val_dense_2_loss: 0.3444 - val_dense_3_loss: 0.4002 - val_dense_2_root_mean_squared_error: 0.5869 - val_dense_3_root_mean_squared_error: 0.6326\n",
      "Epoch 17/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3389 - dense_2_loss: 0.3322 - dense_3_loss: 0.3992 - dense_2_root_mean_squared_error: 0.5764 - dense_3_root_mean_squared_error: 0.6318 - val_loss: 0.3536 - val_dense_2_loss: 0.3476 - val_dense_3_loss: 0.4082 - val_dense_2_root_mean_squared_error: 0.5896 - val_dense_3_root_mean_squared_error: 0.6389\n",
      "Epoch 18/20\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3314 - dense_2_loss: 0.3247 - dense_3_loss: 0.3921 - dense_2_root_mean_squared_error: 0.5698 - dense_3_root_mean_squared_error: 0.6262 - val_loss: 0.3468 - val_dense_2_loss: 0.3412 - val_dense_3_loss: 0.3975 - val_dense_2_root_mean_squared_error: 0.5841 - val_dense_3_root_mean_squared_error: 0.6305\n",
      "Epoch 19/20\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3326 - dense_2_loss: 0.3262 - dense_3_loss: 0.3896 - dense_2_root_mean_squared_error: 0.5712 - dense_3_root_mean_squared_error: 0.6242 - val_loss: 0.3422 - val_dense_2_loss: 0.3364 - val_dense_3_loss: 0.3942 - val_dense_2_root_mean_squared_error: 0.5800 - val_dense_3_root_mean_squared_error: 0.6278\n",
      "Epoch 20/20\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3284 - dense_2_loss: 0.3219 - dense_3_loss: 0.3864 - dense_2_root_mean_squared_error: 0.5674 - dense_3_root_mean_squared_error: 0.6216 - val_loss: 0.3450 - val_dense_2_loss: 0.3395 - val_dense_3_loss: 0.3939 - val_dense_2_root_mean_squared_error: 0.5827 - val_dense_3_root_mean_squared_error: 0.6276\n"
     ]
    }
   ],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep],\n",
    "                       outputs=[output, aux_output])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer,\n",
    "              metrics=[\"RootMeanSquaredError\"])\n",
    "# Higher version\n",
    "#model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer,\n",
    "#              metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"])\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.3578 - dense_2_loss: 0.3524 - dense_3_loss: 0.4064 - dense_2_root_mean_squared_error: 0.5936 - dense_3_root_mean_squared_error: 0.6375\n",
      "[0.3577599823474884, 0.35235825181007385, 0.40637466311454773, 0.5935977101325989, 0.6374751925468445]\n",
      "weighted_sum_of_rmses:  0.5979854583740235\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "print(eval_results)\n",
    "weighted_sum_of_rmse = eval_results[3]*0.9 + eval_results[4]*0.1\n",
    "print(\"weighted_sum_of_rmses: \", weighted_sum_of_rmse)\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)  # needed to support naming the model\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output\n",
    "\n",
    "tf.random.set_seed(42)  # extra code – just for reproducibility\n",
    "model1 = WideAndDeepModel(30, activation=\"relu\", name=\"my_cool_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 1.1607 - output_1_loss: 1.0963 - output_2_loss: 1.7405 - output_1_root_mean_squared_error: 1.0470 - output_2_root_mean_squared_error: 1.3193 - val_loss: 0.5530 - val_output_1_loss: 0.5194 - val_output_2_loss: 0.8554 - val_output_1_root_mean_squared_error: 0.7207 - val_output_2_root_mean_squared_error: 0.9249\n",
      "Epoch 2/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.4833 - output_1_loss: 0.4525 - output_2_loss: 0.7607 - output_1_root_mean_squared_error: 0.6727 - output_2_root_mean_squared_error: 0.8722 - val_loss: 0.4477 - val_output_1_loss: 0.4270 - val_output_2_loss: 0.6337 - val_output_1_root_mean_squared_error: 0.6535 - val_output_2_root_mean_squared_error: 0.7961\n",
      "Epoch 3/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.4282 - output_1_loss: 0.4083 - output_2_loss: 0.6077 - output_1_root_mean_squared_error: 0.6390 - output_2_root_mean_squared_error: 0.7795 - val_loss: 0.4275 - val_output_1_loss: 0.4115 - val_output_2_loss: 0.5716 - val_output_1_root_mean_squared_error: 0.6414 - val_output_2_root_mean_squared_error: 0.7560\n",
      "Epoch 4/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.4029 - output_1_loss: 0.3864 - output_2_loss: 0.5515 - output_1_root_mean_squared_error: 0.6216 - output_2_root_mean_squared_error: 0.7426 - val_loss: 0.4210 - val_output_1_loss: 0.4077 - val_output_2_loss: 0.5403 - val_output_1_root_mean_squared_error: 0.6385 - val_output_2_root_mean_squared_error: 0.7351\n",
      "Epoch 5/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3867 - output_1_loss: 0.3723 - output_2_loss: 0.5168 - output_1_root_mean_squared_error: 0.6101 - output_2_root_mean_squared_error: 0.7189 - val_loss: 0.3928 - val_output_1_loss: 0.3811 - val_output_2_loss: 0.4981 - val_output_1_root_mean_squared_error: 0.6173 - val_output_2_root_mean_squared_error: 0.7058\n",
      "Epoch 6/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3747 - output_1_loss: 0.3615 - output_2_loss: 0.4930 - output_1_root_mean_squared_error: 0.6013 - output_2_root_mean_squared_error: 0.7022 - val_loss: 0.3871 - val_output_1_loss: 0.3773 - val_output_2_loss: 0.4759 - val_output_1_root_mean_squared_error: 0.6142 - val_output_2_root_mean_squared_error: 0.6899\n",
      "Epoch 7/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3674 - output_1_loss: 0.3557 - output_2_loss: 0.4722 - output_1_root_mean_squared_error: 0.5964 - output_2_root_mean_squared_error: 0.6872 - val_loss: 0.3978 - val_output_1_loss: 0.3909 - val_output_2_loss: 0.4602 - val_output_1_root_mean_squared_error: 0.6252 - val_output_2_root_mean_squared_error: 0.6784\n",
      "Epoch 8/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3807 - output_1_loss: 0.3723 - output_2_loss: 0.4561 - output_1_root_mean_squared_error: 0.6102 - output_2_root_mean_squared_error: 0.6753 - val_loss: 0.3726 - val_output_1_loss: 0.3650 - val_output_2_loss: 0.4409 - val_output_1_root_mean_squared_error: 0.6042 - val_output_2_root_mean_squared_error: 0.6640\n",
      "Epoch 9/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3516 - output_1_loss: 0.3420 - output_2_loss: 0.4380 - output_1_root_mean_squared_error: 0.5848 - output_2_root_mean_squared_error: 0.6618 - val_loss: 0.3654 - val_output_1_loss: 0.3578 - val_output_2_loss: 0.4346 - val_output_1_root_mean_squared_error: 0.5981 - val_output_2_root_mean_squared_error: 0.6593\n",
      "Epoch 10/10\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3476 - output_1_loss: 0.3382 - output_2_loss: 0.4324 - output_1_root_mean_squared_error: 0.5815 - output_2_root_mean_squared_error: 0.6575 - val_loss: 0.3754 - val_output_1_loss: 0.3681 - val_output_2_loss: 0.4408 - val_output_1_root_mean_squared_error: 0.6067 - val_output_2_root_mean_squared_error: 0.6639\n",
      "\n",
      "Evaluating...\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.3794 - output_1_loss: 0.3719 - output_2_loss: 0.4463 - output_1_root_mean_squared_error: 0.6099 - output_2_root_mean_squared_error: 0.6681\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[0.3793811798095703, 0.37194573879241943, 0.44629985094070435, 0.6098735332489014, 0.6680567860603333]\n",
      "weighted_sum_of_rmses:  0.6156918585300446\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model1.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer,\n",
    "              metrics=[\"RootMeanSquaredError\"])\n",
    "# Higher version\n",
    "#model1.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer,\n",
    "#              metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"])\n",
    "model1.norm_layer_wide.adapt(X_train_wide)\n",
    "model1.norm_layer_deep.adapt(X_train_deep)\n",
    "history = model1.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)))\n",
    "print(\"\\nEvaluating...\")\n",
    "eval_results1 = model1.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model1.predict((X_new_wide, X_new_deep))\n",
    "print(eval_results1)\n",
    "weighted_sum_of_rmse1 = eval_results1[3]*0.9 + eval_results1[4]*0.1\n",
    "#Higher version\n",
    "#weighted_sum_of_rmse = eval_results1[1]*0.9 + eval_results1[5]*0.1\n",
    "print(\"weighted_sum_of_rmses: \", weighted_sum_of_rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – delete the directory, in case it already exists\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"my_keras_model\", ignore_errors=True)\n",
    "shutil.rmtree(\"my_keras_model1\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "INFO:tensorflow:Assets written to: my_keras_model\\assets\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "INFO:tensorflow:Assets written to: my_keras_model1\\assets\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 직전에 추가\n",
    "# 모델 호출하여 입력 형태 정의 \n",
    "model.predict((X_new_wide, X_new_deep))\n",
    "model.save(\"my_keras_model\", save_format=\"tf\")\n",
    "\n",
    "# 모델1 호출하여 입력 형태 정의\n",
    "model1.predict((X_new_wide, X_new_deep)) \n",
    "model1.save(\"my_keras_model1\", save_format=\"tf\")\n",
    "# Higher version\n",
    "#model.export(\"my_keras_model\")\n",
    "#model1.export(\"my_keras_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_keras_model\\assets\n",
      "my_keras_model\\keras_metadata.pb\n",
      "my_keras_model\\saved_model.pb\n",
      "my_keras_model\\variables\n",
      "my_keras_model\\variables\\variables.data-00000-of-00001\n",
      "my_keras_model\\variables\\variables.index\n"
     ]
    }
   ],
   "source": [
    "# extra code – show the contents of the my_keras_model/ directory. TF2.8 only\n",
    "for path in sorted(Path(\"my_keras_model\").glob(\"**/*\")):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model(\"my_keras_model\")\n",
    "model3 = tf.keras.models.load_model(\"my_keras_model1\")\n",
    "y_pred_main, y_pred_aux = model3.predict((X_new_wide, X_new_deep))\n",
    "#Higher version\n",
    "#tfsm_layer = tf.keras.layers.TFSMLayer(\"my_keras_model1\")\n",
    "#y_pred_main, y_pred_aux = tfsm_layer((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_weights\")\n",
    "model1.save_weights(\"my_weights\")\n",
    "#HIgher version\n",
    "#model.save_weights(\"my_weights.weights.h5\")\n",
    "#model1.save_weights(\"my_weights1.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2c125198e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_weights\")\n",
    "model1.load_weights(\"my_weights\")\n",
    "#HIgher version\n",
    "#model.load_weights(\"my_weights.weights.h5\")\n",
    "#model1.load_weights(\"my_weights1.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For higher versions, to save a model using the `.keras` format, simply use `model.save()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Higher version\n",
    "#model.save(\"my_model.keras\")\n",
    "#model1.save(\"my_model1.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For higher versions, to load a `.keras` model, use the `tf.keras.models.load_model()` function. If the model uses any custom object, you must pass them to the function via the `custom_objects` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = tf.keras.models.load_model(\"my_model.keras\")\n",
    "#loaded_model1 = tf.keras.models.load_model(\n",
    "#    \"my_model1.keras\",\n",
    "#    custom_objects={\"WideAndDeepModel\": WideAndDeepModel}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_weights.data-00000-of-00001\n",
      "my_weights.index\n"
     ]
    }
   ],
   "source": [
    "# extra code – show the list of my_weights.* files\n",
    "for path in sorted(Path().glob(\"my_weights.*\")):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==P1. Saving and Restoring==\n",
    "#### model1와 model3 (또는 loaded_model1)에 대해 X_test_wide, X_test_deep의 입력을 이용하여 evaluate 결과를 구하여 원래의 값과 비교하시오.\n",
    "#### Answer.\n",
    "- 서로 다른 객체임에도 불구하고 정확히 똑같은 값을 나타내었다.\n",
    "- 평가 결과 비교:\n",
    "  - 총 손실(Loss): 원본 모델 0.3763 = 로드된 모델 0.3763 (차이: 0.0)\n",
    "  - 주 출력 손실(Main output loss): 원본 모델 0.3697 = 로드된 모델 0.3697 (차이: 0.0)\n",
    "  - 보조 출력 손실(Aux output loss): 원본 모델 0.4362 = 로드된 모델 0.4362 (차이: 0.0)\n",
    "  - 주 출력 RMSE: 원본 모델 0.6080 = 로드된 모델 0.6080 (차이: 0.0)\n",
    "  - 보조 출력 RMSE: 원본 모델 0.6604 = 로드된 모델 0.6604 (차이: 0.0)\n",
    "- 이는 TensorFlow의 모델 저장 및 로드 기능이 모델의 구조와 가중치를 정확하게 보존함을 증명한다.\n",
    "- 추가 테스트에서도 서로 다른 객체이며(model1 is model3: False), 수정된 입력에 대해서도 동일한 예측을 수행하는 것을 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model evaluation:\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.3794 - output_1_loss: 0.3719 - output_2_loss: 0.4463 - output_1_root_mean_squared_error: 0.6099 - output_2_root_mean_squared_error: 0.6681\n",
      "Original model - Loss: 0.3793811798095703\n",
      "Original model - Main output loss: 0.37194573879241943\n",
      "Original model - Aux output loss: 0.44629985094070435\n",
      "Original model - Main output RMSE: 0.6098735332489014\n",
      "Original model - Aux output RMSE: 0.6680567860603333\n",
      "\n",
      "Loaded model evaluation:\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.3794 - output_1_loss: 0.3719 - output_2_loss: 0.4463 - output_1_root_mean_squared_error: 0.6099 - output_2_root_mean_squared_error: 0.6681\n",
      "Loaded model - Loss: 0.3793811798095703\n",
      "Loaded model - Main output loss: 0.37194573879241943\n",
      "Loaded model - Aux output loss: 0.44629985094070435\n",
      "Loaded model - Main output RMSE: 0.6098735332489014\n",
      "Loaded model - Aux output RMSE: 0.6680567860603333\n",
      "\n",
      "Comparison:\n",
      "Total loss difference: 0.0\n",
      "Main output loss difference: 0.0\n",
      "Aux output loss difference: 0.0\n",
      "Main output RMSE difference: 0.0\n",
      "Aux output RMSE difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 원래 모델(model1) 평가\n",
    "print(\"Original model evaluation:\")\n",
    "eval_results1 = model1.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "print(\"Original model - Loss:\", eval_results1[0])\n",
    "print(\"Original model - Main output loss:\", eval_results1[1])\n",
    "print(\"Original model - Aux output loss:\", eval_results1[2])\n",
    "print(\"Original model - Main output RMSE:\", eval_results1[3])\n",
    "print(\"Original model - Aux output RMSE:\", eval_results1[4])\n",
    "\n",
    "# 불러온 모델(model3) 평가\n",
    "print(\"\\nLoaded model evaluation:\")\n",
    "eval_results3 = model3.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "print(\"Loaded model - Loss:\", eval_results3[0])\n",
    "print(\"Loaded model - Main output loss:\", eval_results3[1])\n",
    "print(\"Loaded model - Aux output loss:\", eval_results3[2])\n",
    "print(\"Loaded model - Main output RMSE:\", eval_results3[3])\n",
    "print(\"Loaded model - Aux output RMSE:\", eval_results3[4])\n",
    "\n",
    "# 결과 비교\n",
    "print(\"\\nComparison:\")\n",
    "print(\"Total loss difference:\", abs(eval_results1[0] - eval_results3[0]))\n",
    "print(\"Main output loss difference:\", abs(eval_results1[1] - eval_results3[1]))\n",
    "print(\"Aux output loss difference:\", abs(eval_results1[2] - eval_results3[2]))\n",
    "print(\"Main output RMSE difference:\", abs(eval_results1[3] - eval_results3[3]))\n",
    "print(\"Aux output RMSE difference:\", abs(eval_results1[4] - eval_results3[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are the same object: False\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Modified input predictions:\n",
      "Original model: [[0.4683363]]\n",
      "Loaded model: [[0.4683363]]\n",
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 구분을 위해 서로 다른 예측을 하는지 확인\n",
    "print(\"Models are the same object:\", model1 is model3)  # False여야 함\n",
    "\n",
    "# 약간 다른 입력으로 두 모델의 출력 비교\n",
    "import numpy as np\n",
    "X_test_modified = X_test_wide.copy()\n",
    "if X_test_modified.shape[0] > 0:\n",
    "    X_test_modified[0, 0] += 0.01  # 첫 번째 샘플의 첫 번째 특성 약간 수정\n",
    "    \n",
    "# 원본 모델과 로드된 모델이 수정된 입력에 대해 동일하게 반응하는지 확인\n",
    "y_pred1_mod, _ = model1.predict((X_test_modified[:1], X_test_deep[:1]))\n",
    "y_pred3_mod, _ = model3.predict((X_test_modified[:1], X_test_deep[:1]))\n",
    "print(\"Modified input predictions:\")\n",
    "print(\"Original model:\", y_pred1_mod)\n",
    "print(\"Loaded model:\", y_pred3_mod)\n",
    "print(\"Difference:\", np.abs(y_pred1_mod - y_pred3_mod).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"my_checkpoints1\", ignore_errors=True)  # extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3451 - output_1_loss: 0.3370 - output_2_loss: 0.4185 - output_1_root_mean_squared_error: 0.5805 - output_2_root_mean_squared_error: 0.6470 - val_loss: 0.3808 - val_output_1_loss: 0.3739 - val_output_2_loss: 0.4431 - val_output_1_root_mean_squared_error: 0.6115 - val_output_2_root_mean_squared_error: 0.6656\n",
      "Epoch 2/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3411 - output_1_loss: 0.3327 - output_2_loss: 0.4169 - output_1_root_mean_squared_error: 0.5768 - output_2_root_mean_squared_error: 0.6457 - val_loss: 0.3683 - val_output_1_loss: 0.3630 - val_output_2_loss: 0.4159 - val_output_1_root_mean_squared_error: 0.6025 - val_output_2_root_mean_squared_error: 0.6449\n",
      "Epoch 3/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3520 - output_1_loss: 0.3447 - output_2_loss: 0.4181 - output_1_root_mean_squared_error: 0.5871 - output_2_root_mean_squared_error: 0.6466 - val_loss: 0.3482 - val_output_1_loss: 0.3415 - val_output_2_loss: 0.4080 - val_output_1_root_mean_squared_error: 0.5844 - val_output_2_root_mean_squared_error: 0.6387\n",
      "Epoch 4/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3362 - output_1_loss: 0.3285 - output_2_loss: 0.4050 - output_1_root_mean_squared_error: 0.5732 - output_2_root_mean_squared_error: 0.6364 - val_loss: 0.3622 - val_output_1_loss: 0.3562 - val_output_2_loss: 0.4161 - val_output_1_root_mean_squared_error: 0.5969 - val_output_2_root_mean_squared_error: 0.6450\n",
      "Epoch 5/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3294 - output_1_loss: 0.3222 - output_2_loss: 0.3947 - output_1_root_mean_squared_error: 0.5676 - output_2_root_mean_squared_error: 0.6283 - val_loss: 0.3405 - val_output_1_loss: 0.3349 - val_output_2_loss: 0.3906 - val_output_1_root_mean_squared_error: 0.5787 - val_output_2_root_mean_squared_error: 0.6250\n",
      "Epoch 6/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3284 - output_1_loss: 0.3213 - output_2_loss: 0.3930 - output_1_root_mean_squared_error: 0.5668 - output_2_root_mean_squared_error: 0.6269 - val_loss: 0.3434 - val_output_1_loss: 0.3380 - val_output_2_loss: 0.3919 - val_output_1_root_mean_squared_error: 0.5814 - val_output_2_root_mean_squared_error: 0.6260\n",
      "Epoch 7/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3278 - output_1_loss: 0.3208 - output_2_loss: 0.3914 - output_1_root_mean_squared_error: 0.5664 - output_2_root_mean_squared_error: 0.6256 - val_loss: 0.3414 - val_output_1_loss: 0.3363 - val_output_2_loss: 0.3876 - val_output_1_root_mean_squared_error: 0.5799 - val_output_2_root_mean_squared_error: 0.6226\n",
      "Epoch 8/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3410 - output_1_loss: 0.3354 - output_2_loss: 0.3914 - output_1_root_mean_squared_error: 0.5792 - output_2_root_mean_squared_error: 0.6256 - val_loss: 0.3404 - val_output_1_loss: 0.3349 - val_output_2_loss: 0.3895 - val_output_1_root_mean_squared_error: 0.5787 - val_output_2_root_mean_squared_error: 0.6241\n",
      "Epoch 9/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3233 - output_1_loss: 0.3166 - output_2_loss: 0.3839 - output_1_root_mean_squared_error: 0.5626 - output_2_root_mean_squared_error: 0.6196 - val_loss: 0.3411 - val_output_1_loss: 0.3355 - val_output_2_loss: 0.3914 - val_output_1_root_mean_squared_error: 0.5792 - val_output_2_root_mean_squared_error: 0.6256\n",
      "Epoch 10/10\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3241 - output_1_loss: 0.3173 - output_2_loss: 0.3847 - output_1_root_mean_squared_error: 0.5633 - output_2_root_mean_squared_error: 0.6202 - val_loss: 0.3510 - val_output_1_loss: 0.3447 - val_output_2_loss: 0.4080 - val_output_1_root_mean_squared_error: 0.5871 - val_output_2_root_mean_squared_error: 0.6388\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints1\",save_weights_only=True)\n",
    "# Higher version\n",
    "#checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints1.weights.h5\",save_weights_only=True)\n",
    "history = model1.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3214 - output_1_loss: 0.3147 - output_2_loss: 0.3821 - output_1_root_mean_squared_error: 0.5609 - output_2_root_mean_squared_error: 0.6182 - val_loss: 0.3433 - val_output_1_loss: 0.3376 - val_output_2_loss: 0.3940 - val_output_1_root_mean_squared_error: 0.5811 - val_output_2_root_mean_squared_error: 0.6277\n",
      "Epoch 2/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3209 - output_1_loss: 0.3142 - output_2_loss: 0.3812 - output_1_root_mean_squared_error: 0.5605 - output_2_root_mean_squared_error: 0.6175 - val_loss: 0.3398 - val_output_1_loss: 0.3334 - val_output_2_loss: 0.3982 - val_output_1_root_mean_squared_error: 0.5774 - val_output_2_root_mean_squared_error: 0.6311\n",
      "Epoch 3/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3311 - output_1_loss: 0.3240 - output_2_loss: 0.3948 - output_1_root_mean_squared_error: 0.5692 - output_2_root_mean_squared_error: 0.6283 - val_loss: 0.3411 - val_output_1_loss: 0.3355 - val_output_2_loss: 0.3909 - val_output_1_root_mean_squared_error: 0.5792 - val_output_2_root_mean_squared_error: 0.6252\n",
      "Epoch 4/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3161 - output_1_loss: 0.3098 - output_2_loss: 0.3731 - output_1_root_mean_squared_error: 0.5566 - output_2_root_mean_squared_error: 0.6108 - val_loss: 0.3466 - val_output_1_loss: 0.3412 - val_output_2_loss: 0.3956 - val_output_1_root_mean_squared_error: 0.5841 - val_output_2_root_mean_squared_error: 0.6290\n",
      "Epoch 5/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3141 - output_1_loss: 0.3078 - output_2_loss: 0.3707 - output_1_root_mean_squared_error: 0.5548 - output_2_root_mean_squared_error: 0.6089 - val_loss: 0.3305 - val_output_1_loss: 0.3257 - val_output_2_loss: 0.3732 - val_output_1_root_mean_squared_error: 0.5707 - val_output_2_root_mean_squared_error: 0.6109\n",
      "Epoch 6/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3187 - output_1_loss: 0.3124 - output_2_loss: 0.3760 - output_1_root_mean_squared_error: 0.5589 - output_2_root_mean_squared_error: 0.6132 - val_loss: 0.3313 - val_output_1_loss: 0.3262 - val_output_2_loss: 0.3768 - val_output_1_root_mean_squared_error: 0.5711 - val_output_2_root_mean_squared_error: 0.6138\n",
      "Epoch 7/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3140 - output_1_loss: 0.3077 - output_2_loss: 0.3709 - output_1_root_mean_squared_error: 0.5547 - output_2_root_mean_squared_error: 0.6090 - val_loss: 0.3290 - val_output_1_loss: 0.3241 - val_output_2_loss: 0.3729 - val_output_1_root_mean_squared_error: 0.5693 - val_output_2_root_mean_squared_error: 0.6107\n",
      "Epoch 8/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3176 - output_1_loss: 0.3118 - output_2_loss: 0.3701 - output_1_root_mean_squared_error: 0.5584 - output_2_root_mean_squared_error: 0.6084 - val_loss: 0.3309 - val_output_1_loss: 0.3257 - val_output_2_loss: 0.3778 - val_output_1_root_mean_squared_error: 0.5707 - val_output_2_root_mean_squared_error: 0.6147\n",
      "Epoch 9/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3111 - output_1_loss: 0.3049 - output_2_loss: 0.3673 - output_1_root_mean_squared_error: 0.5521 - output_2_root_mean_squared_error: 0.6061 - val_loss: 0.3361 - val_output_1_loss: 0.3312 - val_output_2_loss: 0.3801 - val_output_1_root_mean_squared_error: 0.5755 - val_output_2_root_mean_squared_error: 0.6166\n",
      "Epoch 10/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3131 - output_1_loss: 0.3069 - output_2_loss: 0.3693 - output_1_root_mean_squared_error: 0.5539 - output_2_root_mean_squared_error: 0.6077 - val_loss: 0.3448 - val_output_1_loss: 0.3394 - val_output_2_loss: 0.3927 - val_output_1_root_mean_squared_error: 0.5826 - val_output_2_root_mean_squared_error: 0.6267\n",
      "Epoch 11/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3140 - output_1_loss: 0.3080 - output_2_loss: 0.3676 - output_1_root_mean_squared_error: 0.5550 - output_2_root_mean_squared_error: 0.6063 - val_loss: 0.3256 - val_output_1_loss: 0.3199 - val_output_2_loss: 0.3774 - val_output_1_root_mean_squared_error: 0.5656 - val_output_2_root_mean_squared_error: 0.6143\n",
      "Epoch 12/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3121 - output_1_loss: 0.3062 - output_2_loss: 0.3650 - output_1_root_mean_squared_error: 0.5533 - output_2_root_mean_squared_error: 0.6042 - val_loss: 0.3298 - val_output_1_loss: 0.3251 - val_output_2_loss: 0.3727 - val_output_1_root_mean_squared_error: 0.5702 - val_output_2_root_mean_squared_error: 0.6105\n",
      "Epoch 13/100\n",
      "465/465 [==============================] - 2s 4ms/step - loss: 0.3080 - output_1_loss: 0.3019 - output_2_loss: 0.3628 - output_1_root_mean_squared_error: 0.5495 - output_2_root_mean_squared_error: 0.6023 - val_loss: 0.3319 - val_output_1_loss: 0.3265 - val_output_2_loss: 0.3804 - val_output_1_root_mean_squared_error: 0.5714 - val_output_2_root_mean_squared_error: 0.6168\n",
      "Epoch 14/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3061 - output_1_loss: 0.3001 - output_2_loss: 0.3602 - output_1_root_mean_squared_error: 0.5478 - output_2_root_mean_squared_error: 0.6002 - val_loss: 0.3302 - val_output_1_loss: 0.3254 - val_output_2_loss: 0.3732 - val_output_1_root_mean_squared_error: 0.5704 - val_output_2_root_mean_squared_error: 0.6109\n",
      "Epoch 15/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3053 - output_1_loss: 0.2994 - output_2_loss: 0.3581 - output_1_root_mean_squared_error: 0.5472 - output_2_root_mean_squared_error: 0.5984 - val_loss: 0.3270 - val_output_1_loss: 0.3217 - val_output_2_loss: 0.3750 - val_output_1_root_mean_squared_error: 0.5672 - val_output_2_root_mean_squared_error: 0.6124\n",
      "Epoch 16/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3057 - output_1_loss: 0.2998 - output_2_loss: 0.3588 - output_1_root_mean_squared_error: 0.5475 - output_2_root_mean_squared_error: 0.5990 - val_loss: 0.3252 - val_output_1_loss: 0.3199 - val_output_2_loss: 0.3726 - val_output_1_root_mean_squared_error: 0.5656 - val_output_2_root_mean_squared_error: 0.6104\n",
      "Epoch 17/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3033 - output_1_loss: 0.2974 - output_2_loss: 0.3567 - output_1_root_mean_squared_error: 0.5453 - output_2_root_mean_squared_error: 0.5972 - val_loss: 0.3214 - val_output_1_loss: 0.3165 - val_output_2_loss: 0.3656 - val_output_1_root_mean_squared_error: 0.5626 - val_output_2_root_mean_squared_error: 0.6046\n",
      "Epoch 18/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3030 - output_1_loss: 0.2972 - output_2_loss: 0.3547 - output_1_root_mean_squared_error: 0.5452 - output_2_root_mean_squared_error: 0.5956 - val_loss: 0.3247 - val_output_1_loss: 0.3198 - val_output_2_loss: 0.3695 - val_output_1_root_mean_squared_error: 0.5655 - val_output_2_root_mean_squared_error: 0.6078\n",
      "Epoch 19/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3042 - output_1_loss: 0.2986 - output_2_loss: 0.3552 - output_1_root_mean_squared_error: 0.5464 - output_2_root_mean_squared_error: 0.5960 - val_loss: 0.3199 - val_output_1_loss: 0.3149 - val_output_2_loss: 0.3648 - val_output_1_root_mean_squared_error: 0.5612 - val_output_2_root_mean_squared_error: 0.6040\n",
      "Epoch 20/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3034 - output_1_loss: 0.2977 - output_2_loss: 0.3551 - output_1_root_mean_squared_error: 0.5456 - output_2_root_mean_squared_error: 0.5959 - val_loss: 0.3232 - val_output_1_loss: 0.3182 - val_output_2_loss: 0.3679 - val_output_1_root_mean_squared_error: 0.5641 - val_output_2_root_mean_squared_error: 0.6065\n",
      "Epoch 21/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.3007 - output_1_loss: 0.2949 - output_2_loss: 0.3530 - output_1_root_mean_squared_error: 0.5431 - output_2_root_mean_squared_error: 0.5941 - val_loss: 0.3219 - val_output_1_loss: 0.3172 - val_output_2_loss: 0.3642 - val_output_1_root_mean_squared_error: 0.5632 - val_output_2_root_mean_squared_error: 0.6035\n",
      "Epoch 22/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3052 - output_1_loss: 0.2999 - output_2_loss: 0.3523 - output_1_root_mean_squared_error: 0.5477 - output_2_root_mean_squared_error: 0.5935 - val_loss: 0.3266 - val_output_1_loss: 0.3218 - val_output_2_loss: 0.3705 - val_output_1_root_mean_squared_error: 0.5672 - val_output_2_root_mean_squared_error: 0.6087\n",
      "Epoch 23/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2970 - output_1_loss: 0.2912 - output_2_loss: 0.3487 - output_1_root_mean_squared_error: 0.5397 - output_2_root_mean_squared_error: 0.5905 - val_loss: 0.3210 - val_output_1_loss: 0.3160 - val_output_2_loss: 0.3657 - val_output_1_root_mean_squared_error: 0.5622 - val_output_2_root_mean_squared_error: 0.6047\n",
      "Epoch 24/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2985 - output_1_loss: 0.2929 - output_2_loss: 0.3492 - output_1_root_mean_squared_error: 0.5412 - output_2_root_mean_squared_error: 0.5909 - val_loss: 0.3194 - val_output_1_loss: 0.3146 - val_output_2_loss: 0.3626 - val_output_1_root_mean_squared_error: 0.5609 - val_output_2_root_mean_squared_error: 0.6022\n",
      "Epoch 25/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2983 - output_1_loss: 0.2926 - output_2_loss: 0.3494 - output_1_root_mean_squared_error: 0.5409 - output_2_root_mean_squared_error: 0.5911 - val_loss: 0.3111 - val_output_1_loss: 0.3061 - val_output_2_loss: 0.3562 - val_output_1_root_mean_squared_error: 0.5532 - val_output_2_root_mean_squared_error: 0.5968\n",
      "Epoch 26/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2964 - output_1_loss: 0.2909 - output_2_loss: 0.3454 - output_1_root_mean_squared_error: 0.5394 - output_2_root_mean_squared_error: 0.5877 - val_loss: 0.3124 - val_output_1_loss: 0.3072 - val_output_2_loss: 0.3599 - val_output_1_root_mean_squared_error: 0.5542 - val_output_2_root_mean_squared_error: 0.5999\n",
      "Epoch 27/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.3015 - output_1_loss: 0.2955 - output_2_loss: 0.3553 - output_1_root_mean_squared_error: 0.5436 - output_2_root_mean_squared_error: 0.5960 - val_loss: 0.3207 - val_output_1_loss: 0.3156 - val_output_2_loss: 0.3671 - val_output_1_root_mean_squared_error: 0.5617 - val_output_2_root_mean_squared_error: 0.6059\n",
      "Epoch 28/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2949 - output_1_loss: 0.2893 - output_2_loss: 0.3453 - output_1_root_mean_squared_error: 0.5379 - output_2_root_mean_squared_error: 0.5876 - val_loss: 0.3267 - val_output_1_loss: 0.3218 - val_output_2_loss: 0.3708 - val_output_1_root_mean_squared_error: 0.5673 - val_output_2_root_mean_squared_error: 0.6089\n",
      "Epoch 29/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2963 - output_1_loss: 0.2910 - output_2_loss: 0.3438 - output_1_root_mean_squared_error: 0.5395 - output_2_root_mean_squared_error: 0.5864 - val_loss: 0.3223 - val_output_1_loss: 0.3172 - val_output_2_loss: 0.3686 - val_output_1_root_mean_squared_error: 0.5632 - val_output_2_root_mean_squared_error: 0.6071\n",
      "Epoch 30/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2920 - output_1_loss: 0.2865 - output_2_loss: 0.3410 - output_1_root_mean_squared_error: 0.5353 - output_2_root_mean_squared_error: 0.5839 - val_loss: 0.3309 - val_output_1_loss: 0.3258 - val_output_2_loss: 0.3771 - val_output_1_root_mean_squared_error: 0.5708 - val_output_2_root_mean_squared_error: 0.6141\n",
      "Epoch 31/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2921 - output_1_loss: 0.2867 - output_2_loss: 0.3406 - output_1_root_mean_squared_error: 0.5355 - output_2_root_mean_squared_error: 0.5836 - val_loss: 0.3238 - val_output_1_loss: 0.3183 - val_output_2_loss: 0.3734 - val_output_1_root_mean_squared_error: 0.5642 - val_output_2_root_mean_squared_error: 0.6111\n",
      "Epoch 32/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2928 - output_1_loss: 0.2874 - output_2_loss: 0.3407 - output_1_root_mean_squared_error: 0.5361 - output_2_root_mean_squared_error: 0.5837 - val_loss: 0.3161 - val_output_1_loss: 0.3110 - val_output_2_loss: 0.3614 - val_output_1_root_mean_squared_error: 0.5577 - val_output_2_root_mean_squared_error: 0.6012\n",
      "Epoch 33/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2959 - output_1_loss: 0.2907 - output_2_loss: 0.3428 - output_1_root_mean_squared_error: 0.5392 - output_2_root_mean_squared_error: 0.5855 - val_loss: 0.3087 - val_output_1_loss: 0.3042 - val_output_2_loss: 0.3492 - val_output_1_root_mean_squared_error: 0.5516 - val_output_2_root_mean_squared_error: 0.5909\n",
      "Epoch 34/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2909 - output_1_loss: 0.2858 - output_2_loss: 0.3368 - output_1_root_mean_squared_error: 0.5346 - output_2_root_mean_squared_error: 0.5804 - val_loss: 0.3349 - val_output_1_loss: 0.3300 - val_output_2_loss: 0.3794 - val_output_1_root_mean_squared_error: 0.5744 - val_output_2_root_mean_squared_error: 0.6160\n",
      "Epoch 35/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2909 - output_1_loss: 0.2857 - output_2_loss: 0.3376 - output_1_root_mean_squared_error: 0.5345 - output_2_root_mean_squared_error: 0.5810 - val_loss: 0.3176 - val_output_1_loss: 0.3129 - val_output_2_loss: 0.3600 - val_output_1_root_mean_squared_error: 0.5594 - val_output_2_root_mean_squared_error: 0.6000\n",
      "Epoch 36/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2890 - output_1_loss: 0.2839 - output_2_loss: 0.3351 - output_1_root_mean_squared_error: 0.5328 - output_2_root_mean_squared_error: 0.5789 - val_loss: 0.3191 - val_output_1_loss: 0.3142 - val_output_2_loss: 0.3634 - val_output_1_root_mean_squared_error: 0.5605 - val_output_2_root_mean_squared_error: 0.6028\n",
      "Epoch 37/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2879 - output_1_loss: 0.2827 - output_2_loss: 0.3347 - output_1_root_mean_squared_error: 0.5317 - output_2_root_mean_squared_error: 0.5786 - val_loss: 0.3159 - val_output_1_loss: 0.3113 - val_output_2_loss: 0.3577 - val_output_1_root_mean_squared_error: 0.5579 - val_output_2_root_mean_squared_error: 0.5981\n",
      "Epoch 38/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2888 - output_1_loss: 0.2837 - output_2_loss: 0.3347 - output_1_root_mean_squared_error: 0.5326 - output_2_root_mean_squared_error: 0.5785 - val_loss: 0.3213 - val_output_1_loss: 0.3174 - val_output_2_loss: 0.3562 - val_output_1_root_mean_squared_error: 0.5634 - val_output_2_root_mean_squared_error: 0.5968\n",
      "Epoch 39/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2898 - output_1_loss: 0.2847 - output_2_loss: 0.3358 - output_1_root_mean_squared_error: 0.5336 - output_2_root_mean_squared_error: 0.5795 - val_loss: 0.3133 - val_output_1_loss: 0.3089 - val_output_2_loss: 0.3534 - val_output_1_root_mean_squared_error: 0.5558 - val_output_2_root_mean_squared_error: 0.5945\n",
      "Epoch 40/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2872 - output_1_loss: 0.2821 - output_2_loss: 0.3328 - output_1_root_mean_squared_error: 0.5311 - output_2_root_mean_squared_error: 0.5769 - val_loss: 0.3103 - val_output_1_loss: 0.3054 - val_output_2_loss: 0.3542 - val_output_1_root_mean_squared_error: 0.5527 - val_output_2_root_mean_squared_error: 0.5951\n",
      "Epoch 41/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2890 - output_1_loss: 0.2840 - output_2_loss: 0.3340 - output_1_root_mean_squared_error: 0.5329 - output_2_root_mean_squared_error: 0.5780 - val_loss: 0.3054 - val_output_1_loss: 0.3007 - val_output_2_loss: 0.3479 - val_output_1_root_mean_squared_error: 0.5484 - val_output_2_root_mean_squared_error: 0.5899\n",
      "Epoch 42/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2878 - output_1_loss: 0.2828 - output_2_loss: 0.3328 - output_1_root_mean_squared_error: 0.5318 - output_2_root_mean_squared_error: 0.5769 - val_loss: 0.3106 - val_output_1_loss: 0.3059 - val_output_2_loss: 0.3533 - val_output_1_root_mean_squared_error: 0.5531 - val_output_2_root_mean_squared_error: 0.5944\n",
      "Epoch 43/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2873 - output_1_loss: 0.2822 - output_2_loss: 0.3333 - output_1_root_mean_squared_error: 0.5313 - output_2_root_mean_squared_error: 0.5773 - val_loss: 0.3140 - val_output_1_loss: 0.3091 - val_output_2_loss: 0.3586 - val_output_1_root_mean_squared_error: 0.5559 - val_output_2_root_mean_squared_error: 0.5988\n",
      "Epoch 44/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2854 - output_1_loss: 0.2802 - output_2_loss: 0.3318 - output_1_root_mean_squared_error: 0.5294 - output_2_root_mean_squared_error: 0.5760 - val_loss: 0.3056 - val_output_1_loss: 0.3013 - val_output_2_loss: 0.3450 - val_output_1_root_mean_squared_error: 0.5489 - val_output_2_root_mean_squared_error: 0.5873\n",
      "Epoch 45/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2831 - output_1_loss: 0.2779 - output_2_loss: 0.3295 - output_1_root_mean_squared_error: 0.5272 - output_2_root_mean_squared_error: 0.5740 - val_loss: 0.3098 - val_output_1_loss: 0.3050 - val_output_2_loss: 0.3523 - val_output_1_root_mean_squared_error: 0.5523 - val_output_2_root_mean_squared_error: 0.5936\n",
      "Epoch 46/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2835 - output_1_loss: 0.2784 - output_2_loss: 0.3294 - output_1_root_mean_squared_error: 0.5277 - output_2_root_mean_squared_error: 0.5739 - val_loss: 0.3048 - val_output_1_loss: 0.3005 - val_output_2_loss: 0.3432 - val_output_1_root_mean_squared_error: 0.5482 - val_output_2_root_mean_squared_error: 0.5859\n",
      "Epoch 47/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2827 - output_1_loss: 0.2777 - output_2_loss: 0.3277 - output_1_root_mean_squared_error: 0.5270 - output_2_root_mean_squared_error: 0.5725 - val_loss: 0.3106 - val_output_1_loss: 0.3061 - val_output_2_loss: 0.3509 - val_output_1_root_mean_squared_error: 0.5533 - val_output_2_root_mean_squared_error: 0.5924\n",
      "Epoch 48/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2837 - output_1_loss: 0.2788 - output_2_loss: 0.3285 - output_1_root_mean_squared_error: 0.5280 - output_2_root_mean_squared_error: 0.5731 - val_loss: 0.3019 - val_output_1_loss: 0.2973 - val_output_2_loss: 0.3427 - val_output_1_root_mean_squared_error: 0.5453 - val_output_2_root_mean_squared_error: 0.5854\n",
      "Epoch 49/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2807 - output_1_loss: 0.2757 - output_2_loss: 0.3257 - output_1_root_mean_squared_error: 0.5250 - output_2_root_mean_squared_error: 0.5707 - val_loss: 0.3048 - val_output_1_loss: 0.3002 - val_output_2_loss: 0.3462 - val_output_1_root_mean_squared_error: 0.5479 - val_output_2_root_mean_squared_error: 0.5884\n",
      "Epoch 50/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2816 - output_1_loss: 0.2767 - output_2_loss: 0.3261 - output_1_root_mean_squared_error: 0.5260 - output_2_root_mean_squared_error: 0.5710 - val_loss: 0.3050 - val_output_1_loss: 0.3007 - val_output_2_loss: 0.3436 - val_output_1_root_mean_squared_error: 0.5483 - val_output_2_root_mean_squared_error: 0.5862\n",
      "Epoch 51/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2810 - output_1_loss: 0.2759 - output_2_loss: 0.3269 - output_1_root_mean_squared_error: 0.5253 - output_2_root_mean_squared_error: 0.5717 - val_loss: 0.3097 - val_output_1_loss: 0.3048 - val_output_2_loss: 0.3531 - val_output_1_root_mean_squared_error: 0.5521 - val_output_2_root_mean_squared_error: 0.5943\n",
      "Epoch 52/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2834 - output_1_loss: 0.2785 - output_2_loss: 0.3273 - output_1_root_mean_squared_error: 0.5277 - output_2_root_mean_squared_error: 0.5721 - val_loss: 0.3121 - val_output_1_loss: 0.3074 - val_output_2_loss: 0.3548 - val_output_1_root_mean_squared_error: 0.5544 - val_output_2_root_mean_squared_error: 0.5956\n",
      "Epoch 53/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2798 - output_1_loss: 0.2749 - output_2_loss: 0.3241 - output_1_root_mean_squared_error: 0.5243 - output_2_root_mean_squared_error: 0.5693 - val_loss: 0.3042 - val_output_1_loss: 0.2998 - val_output_2_loss: 0.3432 - val_output_1_root_mean_squared_error: 0.5476 - val_output_2_root_mean_squared_error: 0.5859\n",
      "Epoch 54/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2802 - output_1_loss: 0.2753 - output_2_loss: 0.3246 - output_1_root_mean_squared_error: 0.5247 - output_2_root_mean_squared_error: 0.5698 - val_loss: 0.3038 - val_output_1_loss: 0.2995 - val_output_2_loss: 0.3423 - val_output_1_root_mean_squared_error: 0.5473 - val_output_2_root_mean_squared_error: 0.5851\n",
      "Epoch 55/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2789 - output_1_loss: 0.2740 - output_2_loss: 0.3230 - output_1_root_mean_squared_error: 0.5235 - output_2_root_mean_squared_error: 0.5683 - val_loss: 0.3031 - val_output_1_loss: 0.2989 - val_output_2_loss: 0.3407 - val_output_1_root_mean_squared_error: 0.5468 - val_output_2_root_mean_squared_error: 0.5837\n",
      "Epoch 56/100\n",
      "465/465 [==============================] - 1s 3ms/step - loss: 0.2798 - output_1_loss: 0.2749 - output_2_loss: 0.3245 - output_1_root_mean_squared_error: 0.5243 - output_2_root_mean_squared_error: 0.5696 - val_loss: 0.3062 - val_output_1_loss: 0.3019 - val_output_2_loss: 0.3451 - val_output_1_root_mean_squared_error: 0.5494 - val_output_2_root_mean_squared_error: 0.5874\n",
      "Epoch 57/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2811 - output_1_loss: 0.2764 - output_2_loss: 0.3238 - output_1_root_mean_squared_error: 0.5257 - output_2_root_mean_squared_error: 0.5690 - val_loss: 0.3284 - val_output_1_loss: 0.3230 - val_output_2_loss: 0.3768 - val_output_1_root_mean_squared_error: 0.5684 - val_output_2_root_mean_squared_error: 0.6139\n",
      "Epoch 58/100\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 0.2799 - output_1_loss: 0.2750 - output_2_loss: 0.3242 - output_1_root_mean_squared_error: 0.5244 - output_2_root_mean_squared_error: 0.5694 - val_loss: 0.3084 - val_output_1_loss: 0.3041 - val_output_2_loss: 0.3466 - val_output_1_root_mean_squared_error: 0.5515 - val_output_2_root_mean_squared_error: 0.5887\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)\n",
    "history = model1.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=100,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, val/train=1.10\n",
      "Epoch=1, val/train=1.10\n",
      "Epoch=2, val/train=1.09\n",
      "Epoch=3, val/train=1.12\n",
      "Epoch=4, val/train=1.09\n",
      "Epoch=5, val/train=1.10\n",
      "Epoch=6, val/train=1.09\n",
      "Epoch=7, val/train=1.08\n",
      "Epoch=8, val/train=1.11\n",
      "Epoch=9, val/train=1.11\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model1.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[val_train_ratio_cb], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is preinstalled on Colab, but not the `tensorboard-plugin-profile`, so let's install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "����: ���μ��� \"17472\"��(��) ã�� �� �����ϴ�.\n"
     ]
    }
   ],
   "source": [
    "# 기존 TensorBoard 프로세스 종료 (Windows)\n",
    "!taskkill /F /PID 17472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:  # extra code\n",
    "    %pip install -q -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"my_logs\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – builds the first regression model we used earlier\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "465/465 [==============================] - 2s 3ms/step - loss: 1.7783 - root_mean_squared_error: 1.3335 - val_loss: 0.8389 - val_root_mean_squared_error: 0.9159\n",
      "Epoch 2/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.7267 - root_mean_squared_error: 0.8525 - val_loss: 0.6542 - val_root_mean_squared_error: 0.8088\n",
      "Epoch 3/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.6302 - root_mean_squared_error: 0.7938 - val_loss: 0.6213 - val_root_mean_squared_error: 0.7882\n",
      "Epoch 4/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.6026 - root_mean_squared_error: 0.7763 - val_loss: 0.5973 - val_root_mean_squared_error: 0.7729\n",
      "Epoch 5/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5787 - root_mean_squared_error: 0.7607 - val_loss: 0.5783 - val_root_mean_squared_error: 0.7605\n",
      "Epoch 6/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5606 - root_mean_squared_error: 0.7487 - val_loss: 0.5602 - val_root_mean_squared_error: 0.7485\n",
      "Epoch 7/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5435 - root_mean_squared_error: 0.7372 - val_loss: 0.5459 - val_root_mean_squared_error: 0.7389\n",
      "Epoch 8/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5286 - root_mean_squared_error: 0.7270 - val_loss: 0.5327 - val_root_mean_squared_error: 0.7298\n",
      "Epoch 9/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5156 - root_mean_squared_error: 0.7181 - val_loss: 0.5207 - val_root_mean_squared_error: 0.7216\n",
      "Epoch 10/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5033 - root_mean_squared_error: 0.7094 - val_loss: 0.5089 - val_root_mean_squared_error: 0.7134\n",
      "Epoch 11/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4926 - root_mean_squared_error: 0.7019 - val_loss: 0.4983 - val_root_mean_squared_error: 0.7059\n",
      "Epoch 12/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4828 - root_mean_squared_error: 0.6949 - val_loss: 0.4902 - val_root_mean_squared_error: 0.7002\n",
      "Epoch 13/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4741 - root_mean_squared_error: 0.6886 - val_loss: 0.4809 - val_root_mean_squared_error: 0.6934\n",
      "Epoch 14/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4660 - root_mean_squared_error: 0.6826 - val_loss: 0.4739 - val_root_mean_squared_error: 0.6884\n",
      "Epoch 15/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4589 - root_mean_squared_error: 0.6774 - val_loss: 0.4662 - val_root_mean_squared_error: 0.6828\n",
      "Epoch 16/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4525 - root_mean_squared_error: 0.6727 - val_loss: 0.4590 - val_root_mean_squared_error: 0.6775\n",
      "Epoch 17/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4466 - root_mean_squared_error: 0.6683 - val_loss: 0.4543 - val_root_mean_squared_error: 0.6740\n",
      "Epoch 18/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4418 - root_mean_squared_error: 0.6647 - val_loss: 0.4488 - val_root_mean_squared_error: 0.6699\n",
      "Epoch 19/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4369 - root_mean_squared_error: 0.6610 - val_loss: 0.4445 - val_root_mean_squared_error: 0.6667\n",
      "Epoch 20/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4330 - root_mean_squared_error: 0.6580 - val_loss: 0.4408 - val_root_mean_squared_error: 0.6639\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir, profile_batch=(100, 200))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_logs\n",
      "  run_2025_03_30_20_58_31\n",
      "    events.out.tfevents.1743335913.CRONG.profile-empty\n",
      "    plugins\n",
      "      profile\n",
      "        2025_03_30_11_58_33\n",
      "          CRONG.input_pipeline.pb\n",
      "          CRONG.kernel_stats.pb\n",
      "          CRONG.memory_profile.json.gz\n",
      "          CRONG.overview_page.pb\n",
      "          CRONG.tensorflow_stats.pb\n",
      "          CRONG.trace.json.gz\n",
      "          CRONG.xplane.pb\n",
      "    train\n",
      "      events.out.tfevents.1743335912.CRONG.25432.4.v2\n",
      "    validation\n",
      "      events.out.tfevents.1743335914.CRONG.25432.5.v2\n"
     ]
    }
   ],
   "source": [
    "print(\"my_logs\")\n",
    "for path in sorted(Path(\"my_logs\").glob(\"**/*\")):\n",
    "    print(\"  \" * (len(path.parts) - 1) + path.parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('my_logs/run_2025_03_30_20_58_52')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=2e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 1.4021 - root_mean_squared_error: 1.1841 - val_loss: 0.7190 - val_root_mean_squared_error: 0.8479\n",
      "Epoch 2/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.6588 - root_mean_squared_error: 0.8117 - val_loss: 0.6021 - val_root_mean_squared_error: 0.7760\n",
      "Epoch 3/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5717 - root_mean_squared_error: 0.7561 - val_loss: 0.5474 - val_root_mean_squared_error: 0.7399\n",
      "Epoch 4/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.5202 - root_mean_squared_error: 0.7213 - val_loss: 0.5120 - val_root_mean_squared_error: 0.7155\n",
      "Epoch 5/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4892 - root_mean_squared_error: 0.6994 - val_loss: 0.4953 - val_root_mean_squared_error: 0.7037\n",
      "Epoch 6/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4760 - root_mean_squared_error: 0.6899 - val_loss: 0.4728 - val_root_mean_squared_error: 0.6876\n",
      "Epoch 7/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4603 - root_mean_squared_error: 0.6784 - val_loss: 0.4639 - val_root_mean_squared_error: 0.6811\n",
      "Epoch 8/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4519 - root_mean_squared_error: 0.6723 - val_loss: 0.4571 - val_root_mean_squared_error: 0.6761\n",
      "Epoch 9/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4427 - root_mean_squared_error: 0.6653 - val_loss: 0.4513 - val_root_mean_squared_error: 0.6718\n",
      "Epoch 10/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4358 - root_mean_squared_error: 0.6602 - val_loss: 0.4457 - val_root_mean_squared_error: 0.6676\n",
      "Epoch 11/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4292 - root_mean_squared_error: 0.6551 - val_loss: 0.4392 - val_root_mean_squared_error: 0.6627\n",
      "Epoch 12/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4252 - root_mean_squared_error: 0.6520 - val_loss: 0.4376 - val_root_mean_squared_error: 0.6615\n",
      "Epoch 13/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4201 - root_mean_squared_error: 0.6481 - val_loss: 0.4317 - val_root_mean_squared_error: 0.6570\n",
      "Epoch 14/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4156 - root_mean_squared_error: 0.6447 - val_loss: 0.4286 - val_root_mean_squared_error: 0.6547\n",
      "Epoch 15/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4116 - root_mean_squared_error: 0.6416 - val_loss: 0.4247 - val_root_mean_squared_error: 0.6517\n",
      "Epoch 16/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4078 - root_mean_squared_error: 0.6386 - val_loss: 0.4200 - val_root_mean_squared_error: 0.6481\n",
      "Epoch 17/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4039 - root_mean_squared_error: 0.6355 - val_loss: 0.4166 - val_root_mean_squared_error: 0.6454\n",
      "Epoch 18/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.4006 - root_mean_squared_error: 0.6329 - val_loss: 0.4139 - val_root_mean_squared_error: 0.6433\n",
      "Epoch 19/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.3976 - root_mean_squared_error: 0.6306 - val_loss: 0.4114 - val_root_mean_squared_error: 0.6414\n",
      "Epoch 20/20\n",
      "465/465 [==============================] - 1s 2ms/step - loss: 0.3946 - root_mean_squared_error: 0.6282 - val_loss: 0.4093 - val_root_mean_squared_error: 0.6398\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23360), started 0:00:07 ago. (Use '!kill 23360' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-98fee32431226337\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-98fee32431226337\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs/\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ### ==P2. Tensorboard==\n",
    " #### 위의 tensorboard에서 한쌍의 train/validation만 선택하고 smoothing slider를 왼쪽으로 움직여 최소값으로 한후 변화를 관찰한다.\n",
    " #### loss와 rmse값의 변화를 관찰하고 학습결과를 분석하시오\n",
    " #### Answer:\n",
    "\n",
    "Smoothing을 최소화하고 관찰한 결과:\n",
    "\n",
    "1. **Loss 변화**: \n",
    "   - 초기에 급격히 감소하다가 5 에포크 이후부터 완만하게 감소한다.\n",
    "   - Validation loss는 0.67에서 시작해 20 에포크에서 0.44까지 낮아진다.\n",
    "\n",
    "2. **RMSE 변화**:\n",
    "   - 초기 RMSE는 0.82에서 시작하여 꾸준히 감소한다.\n",
    "   - 20 에포크에서는 0.66까지 낮아진다.\n",
    "\n",
    "3. **Train과 Validation 비교**:\n",
    "   - 두 곡선이 유사한 패턴으로 감소하며 큰 격차가 없다.\n",
    "   - 이는 모델이 과적합 없이 잘 일반화되고 있음을 보여준다.\n",
    "\n",
    "4. **Smoothing 효과**:\n",
    "   - Smoothing을 0으로 설정해도 곡선이 부드럽다.\n",
    "   - 이는 학습이 안정적으로 진행되었음을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:6006/\">http://localhost:6006/</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import output\n",
    "\n",
    "    output.serve_kernel_port_as_window(6006)\n",
    "else:\n",
    "    from IPython.display import display, HTML\n",
    "\n",
    "    display(HTML('<a href=\"http://localhost:6006/\">http://localhost:6006/</a>'))\n",
    "    \n",
    "# Copy the url below, and paste it on a new tab    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use also visualize histograms, images, text, and even listen to audio using TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(str(test_logdir))\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        \n",
    "        data = (np.random.randn(100) + 2) * step / 100  # gets larger\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        \n",
    "        images = np.random.rand(2, 32, 32, 3) * step / 1000  # gets brighter\n",
    "        tf.summary.image(\"my_images\", images, step=step)\n",
    "        \n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step ** 2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        \n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you stop this Jupyter kernel (a.k.a. Runtime), it will automatically stop the TensorBoard server as well. Another way to stop the TensorBoard server is to kill it, if you are running on Linux or MacOSX. First, you need to find its process ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6007: logdir ./my_logs (started 4:44:36 ago; pid 16756)\n",
      "  - port 6006: logdir ./my_logs (started 1 day, 1:48:34 ago; pid 17472)\n",
      "  - port 6006: logdir ./my_logs/ (started 0:06:13 ago; pid 23360)\n"
     ]
    }
   ],
   "source": [
    "# extra code – lists all running TensorBoard server instances\n",
    "\n",
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll use the Fashion MNIST dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    %pip install -q -U keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 37s]\n",
      "val_accuracy: 0.8392000198364258\n",
      "\n",
      "Best val_accuracy So Far: 0.859000027179718\n",
      "Total elapsed time: 00h 03m 16s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 7,\n",
       " 'n_neurons': 100,\n",
       " 'learning_rate': 0.0012482904754698163,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "top3_params[0].values  # best hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 7\n",
      "n_neurons: 100\n",
      "learning_rate: 0.0012482904754698163\n",
      "optimizer: sgd\n",
      "Score: 0.859000027179718\n"
     ]
    }
   ],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859000027179718"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3298 - accuracy: 0.8790 - val_loss: 0.3899 - val_accuracy: 0.8606\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3181 - accuracy: 0.8823 - val_loss: 0.3626 - val_accuracy: 0.8672\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3106 - accuracy: 0.8864 - val_loss: 0.3301 - val_accuracy: 0.8720\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3017 - accuracy: 0.8900 - val_loss: 0.3301 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2959 - accuracy: 0.8904 - val_loss: 0.3249 - val_accuracy: 0.8762\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2894 - accuracy: 0.8928 - val_loss: 0.3035 - val_accuracy: 0.8856\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2820 - accuracy: 0.8960 - val_loss: 0.3039 - val_accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2774 - accuracy: 0.8984 - val_loss: 0.2820 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2705 - accuracy: 0.9004 - val_loss: 0.2797 - val_accuracy: 0.8918\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2653 - accuracy: 0.9024 - val_loss: 0.2789 - val_accuracy: 0.8920\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8601\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_full, y_train_full, validation_data=(X_valid, y_valid), epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==P3. Random Search==\n",
    "#### 1. 위에서 random search의 seed를 변경하여 search를 진행후 best model의 hyperparameter와 score를 찾아 seed=42인 경우와 비교하시오\n",
    "#### 2. seed=42일 때, max_trials=10으로 변경하여 best model의 hyperparameter와 score를 비교하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 42s]\n",
      "val_accuracy: 0.8551999926567078\n",
      "\n",
      "Best val_accuracy So Far: 0.8705999851226807\n",
      "Total elapsed time: 00h 03m 00s\n",
      "Best hyperparameters (seed=100): {'n_hidden': 8, 'n_neurons': 227, 'learning_rate': 0.0026385629878377535, 'optimizer': 'sgd'}\n",
      "Best score (seed=100): 0.8705999851226807\n"
     ]
    }
   ],
   "source": [
    "# P3.1 코드: 다른 seed 값으로 random search 실행\n",
    "random_search_tuner1 = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search1\", seed=100)  # seed 값을 42에서 100으로 변경\n",
    "random_search_tuner1.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))\n",
    "\n",
    "# 최적의 하이퍼파라미터 확인\n",
    "top3_params1 = random_search_tuner1.get_best_hyperparameters(num_trials=1)\n",
    "print(\"Best hyperparameters (seed=100):\", top3_params1[0].values)\n",
    "best_trial1 = random_search_tuner1.oracle.get_best_trials(num_trials=1)[0]\n",
    "print(\"Best score (seed=100):\", best_trial1.metrics.get_last_value(\"val_accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (seed=42): {'n_hidden': 7, 'n_neurons': 100, 'learning_rate': 0.0012482904754698163, 'optimizer': 'sgd'}\n",
      "Best score (seed=42): 0.859000027179718\n",
      "\n",
      "=== 비교 결과 ===\n",
      "seed=42 (원래 결과):\n",
      "  - 최적 하이퍼파라미터: {'n_hidden': 7, 'n_neurons': 100, 'learning_rate': 0.0012482904754698163, 'optimizer': 'sgd'}\n",
      "  - 최고 점수: 0.859000027179718\n",
      "\n",
      "seed=100 (새로운 결과):\n",
      "  - 최적 하이퍼파라미터: {'n_hidden': 8, 'n_neurons': 227, 'learning_rate': 0.0026385629878377535, 'optimizer': 'sgd'}\n",
      "  - 최고 점수: 0.8705999851226807\n"
     ]
    }
   ],
   "source": [
    "# 기존 결과(seed=42)의 최적 하이퍼파라미터 확인\n",
    "top3_params_original = random_search_tuner.get_best_hyperparameters(num_trials=1)\n",
    "print(\"Best hyperparameters (seed=42):\", top3_params_original[0].values)\n",
    "best_trial_original = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "print(\"Best score (seed=42):\", best_trial_original.metrics.get_last_value(\"val_accuracy\"))\n",
    "\n",
    "# 이제 모든 결과를 한번에 비교\n",
    "print(\"\\n=== 비교 결과 ===\")\n",
    "print(\"seed=42 (원래 결과):\")\n",
    "print(\"  - 최적 하이퍼파라미터:\", top3_params_original[0].values)\n",
    "print(\"  - 최고 점수:\", best_trial_original.metrics.get_last_value(\"val_accuracy\"))\n",
    "print(\"\\nseed=100 (새로운 결과):\")\n",
    "print(\"  - 최적 하이퍼파라미터:\", top3_params1[0].values)\n",
    "print(\"  - 최고 점수:\", best_trial1.metrics.get_last_value(\"val_accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 46s]\n",
      "val_accuracy: 0.8700000047683716\n",
      "\n",
      "Best val_accuracy So Far: 0.8795999884605408\n",
      "Total elapsed time: 00h 06m 46s\n",
      "Best hyperparameters (max_trials=10): {'n_hidden': 7, 'n_neurons': 124, 'learning_rate': 0.0005509513888645584, 'optimizer': 'adam'}\n",
      "Best score (max_trials=10): 0.8795999884605408\n"
     ]
    }
   ],
   "source": [
    "# P3.2 코드: max_trials=10으로 변경\n",
    "random_search_tuner2 = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=10, overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search2\", seed=42)  # max_trials를 10으로 변경\n",
    "random_search_tuner2.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))\n",
    "\n",
    "# 최적의 하이퍼파라미터 확인\n",
    "top3_params2 = random_search_tuner2.get_best_hyperparameters(num_trials=1)\n",
    "print(\"Best hyperparameters (max_trials=10):\", top3_params2[0].values)\n",
    "best_trial2 = random_search_tuner2.oracle.get_best_trials(num_trials=1)[0]\n",
    "print(\"Best score (max_trials=10):\", best_trial2.metrics.get_last_value(\"val_accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 하이퍼파라미터 탐색 결과 비교 ===\n",
      "         설정         |                         최적 하이퍼파라미터                         |     최고 점수     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "seed=42, trials=5  | {'n_hidden': 7, 'n_neurons': 100, 'learning_rate': 0.0012482904754698163, 'optimizer': 'sgd'} | 0.859000\n",
      "seed=100, trials=5 | {'n_hidden': 8, 'n_neurons': 227, 'learning_rate': 0.0026385629878377535, 'optimizer': 'sgd'} | 0.870600\n",
      "seed=42, trials=10 | {'n_hidden': 7, 'n_neurons': 124, 'learning_rate': 0.0005509513888645584, 'optimizer': 'adam'} | 0.879600\n"
     ]
    }
   ],
   "source": [
    "# 기존 결과(seed=42, max_trials=5)의 최적 하이퍼파라미터 확인\n",
    "top3_params_original = random_search_tuner.get_best_hyperparameters(num_trials=1)\n",
    "best_trial_original = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "\n",
    "# 모든 결과를 표 형태로 비교\n",
    "print(\"\\n=== 하이퍼파라미터 탐색 결과 비교 ===\")\n",
    "print(f\"{'설정':^20}|{'최적 하이퍼파라미터':^60}|{'최고 점수':^15}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"seed=42, trials=5  | {top3_params_original[0].values} | {best_trial_original.metrics.get_last_value('val_accuracy'):.6f}\")\n",
    "print(f\"seed=100, trials=5 | {top3_params1[0].values} | {best_trial1.metrics.get_last_value('val_accuracy'):.6f}\")\n",
    "print(f\"seed=42, trials=10 | {top3_params2[0].values} | {best_trial2.metrics.get_last_value('val_accuracy'):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3 결과 비교 분석\n",
    "#### 1. 시드 변경 효과 (seed=42 vs seed=100, trials=5 유지):\n",
    "    - 시드 변경만으로도 최적 하이퍼파라미터가 크게 달라짐\n",
    "    - 정확도가 0.859에서 0.870으로 약 1.1% 향상됨\n",
    "    - 뉴런 수가 100에서 227로 증가, 은닉층 수는 7에서 8로 증가\n",
    "\n",
    "#### 2. 탐색 횟수 증가 효과 (max_trials=5 vs max_trials=10, seed=42 유지):\n",
    "    - 탐색 횟수 증가로 정확도가 0.859에서 0.879로 약 2% 향상됨\n",
    "    - 최적 하이퍼파라미터의 뉴런 수가 100에서 124로 증가\n",
    "    - 옵티마이저가 sgd에서 adam으로 변경됨\n",
    "\n",
    "#### 3. 종합 분석:\n",
    "    - 탐색 횟수 증가가 시드 변경보다 더 큰 성능 향상을 가져옴\n",
    "    - 최적의 결과는 seed=42, trials=10 설정에서 얻어짐(정확도 0.879)\n",
    "    - 학습률은 전반적으로 낮은 값(0.0005~0.002)이 선호됨\n",
    "    - 은닉층의 수는 7~8개로 비슷하게 유지됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P2 결과비교 \n",
    "#### Answer:\n",
    "seed=42, max_trials=5: #기존\n",
    "\n",
    "\n",
    "\n",
    "seed=100 , max_trials=5: #P3.1\n",
    "\n",
    "\n",
    "\n",
    "seed=42, max_trials=10: #P3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "\n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = tf.keras.layers.Normalization()\n",
    "            X = norm_layer(X)\n",
    "        return model.fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = kt.Hyperband(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", seed=42,\n",
    "    max_epochs=10, factor=3, hyperband_iterations=2,\n",
    "    overwrite=True, directory=\"my_fashion_mnist\", project_name=\"hyperband\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 51s]\n",
      "val_accuracy: 0.8507999777793884\n",
      "\n",
      "Best val_accuracy So Far: 0.8817999958992004\n",
      "Total elapsed time: 00h 17m 44s\n"
     ]
    }
   ],
   "source": [
    "root_logdir = Path(hyperband_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "hyperband_tuner.search(X_train, y_train, epochs=10,\n",
    "                       validation_data=(X_valid, y_valid),\n",
    "                       callbacks=[early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-562aee8873a5587f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-562aee8873a5587f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={root_logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 54s]\n",
      "val_accuracy: 0.8338000178337097\n",
      "\n",
      "Best val_accuracy So Far: 0.8586000204086304\n",
      "Total elapsed time: 00h 09m 27s\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner = kt.BayesianOptimization(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", seed=42,\n",
    "    max_trials=10, alpha=1e-4, beta=2.6,\n",
    "    overwrite=True, directory=\"my_fashion_mnist\", project_name=\"bayesian_opt\")\n",
    "bayesian_opt_tuner.search(X_train, y_train, epochs=10,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.4\n",
    "아래의 파라미터를 갖는 fully-connected network에 대해 다음 물음에 답하시오  \n",
    "Number of input features: Nf  \n",
    "Number of neurons in ith hidden nodes: Nni  \n",
    "Number of hidden layers: Nh  \n",
    "Number of output node: No  \n",
    "\n",
    "1. MAC(multiply and addition) operation의 수를 위에서 주어진 파라미터를 이용하여 식으로 표현하시오. 단, Nh=3이다.  \n",
    "2. 위의 코드중 Reggression MLP의 california housing dataset에 대해 Nh=3, Nn1=Nn2=Nn3=30일 때 30 epoch 동안 학습후 loss, val_loss, mse_test값을 구하시오. Hyperparameter는 Regression MLP의 실습 코드와 같은 값을 이용한다. Tensorboard를 위해 log10 directory에 get_log_dir 함수를 이용하여 subdirectory를 생성하시오.   \n",
    "3. Nh=2일 때 MAC operation 수가 최대한 비슷하도록 Nn1=Nn2를 구하고 2와 같은 조건으로 학습시키고 step당 학습시간, training loss와 test accuracy를 구하시오.\n",
    "4. Nh=1일 때 MAC operation 수가 최대한 비슷하도록 Nn1을 구하고 2와 같은 조건으로 학습시키고 step당 학습시간, training loss와 test accuracy를 구하시오.  \n",
    "5. 2-4번의 결과를 비교하고 분석하시오. 또한 Tensorboard에서 learning curve를 비교하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "MAC 연산 수 = Nf × Nn1 + Nn1 × Nn2 + Nn2 × Nn3 + Nn3 × No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.8806 - root_mean_squared_error: 1.3714 - val_loss: 1.4489 - val_root_mean_squared_error: 1.2037\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7557 - root_mean_squared_error: 0.8693 - val_loss: 0.7680 - val_root_mean_squared_error: 0.8764\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6595 - root_mean_squared_error: 0.8121 - val_loss: 0.6209 - val_root_mean_squared_error: 0.7880\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6057 - root_mean_squared_error: 0.7783 - val_loss: 0.5792 - val_root_mean_squared_error: 0.7610\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5648 - root_mean_squared_error: 0.7516 - val_loss: 0.5206 - val_root_mean_squared_error: 0.7215\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5271 - root_mean_squared_error: 0.7260 - val_loss: 0.4929 - val_root_mean_squared_error: 0.7021\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4982 - root_mean_squared_error: 0.7058 - val_loss: 0.4747 - val_root_mean_squared_error: 0.6890\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4734 - root_mean_squared_error: 0.6880 - val_loss: 0.4549 - val_root_mean_squared_error: 0.6745\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4539 - root_mean_squared_error: 0.6737 - val_loss: 0.4386 - val_root_mean_squared_error: 0.6623\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4384 - root_mean_squared_error: 0.6621 - val_loss: 0.4257 - val_root_mean_squared_error: 0.6524\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4267 - root_mean_squared_error: 0.6532 - val_loss: 0.4071 - val_root_mean_squared_error: 0.6381\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4170 - root_mean_squared_error: 0.6458 - val_loss: 0.3975 - val_root_mean_squared_error: 0.6305\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4091 - root_mean_squared_error: 0.6396 - val_loss: 0.3856 - val_root_mean_squared_error: 0.6209\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4026 - root_mean_squared_error: 0.6345 - val_loss: 0.3791 - val_root_mean_squared_error: 0.6157\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3975 - root_mean_squared_error: 0.6305 - val_loss: 0.3736 - val_root_mean_squared_error: 0.6112\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3929 - root_mean_squared_error: 0.6268 - val_loss: 0.3692 - val_root_mean_squared_error: 0.6076\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3892 - root_mean_squared_error: 0.6238 - val_loss: 0.3664 - val_root_mean_squared_error: 0.6053\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3859 - root_mean_squared_error: 0.6212 - val_loss: 0.3643 - val_root_mean_squared_error: 0.6035\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3825 - root_mean_squared_error: 0.6184 - val_loss: 0.3638 - val_root_mean_squared_error: 0.6031\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3804 - root_mean_squared_error: 0.6168 - val_loss: 0.3680 - val_root_mean_squared_error: 0.6066\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3775 - root_mean_squared_error: 0.6144 - val_loss: 0.3671 - val_root_mean_squared_error: 0.6058\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3754 - root_mean_squared_error: 0.6127 - val_loss: 0.3720 - val_root_mean_squared_error: 0.6099\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3734 - root_mean_squared_error: 0.6111 - val_loss: 0.3587 - val_root_mean_squared_error: 0.5989\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3713 - root_mean_squared_error: 0.6093 - val_loss: 0.3577 - val_root_mean_squared_error: 0.5981\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3697 - root_mean_squared_error: 0.6081 - val_loss: 0.3608 - val_root_mean_squared_error: 0.6006\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3679 - root_mean_squared_error: 0.6066 - val_loss: 0.3618 - val_root_mean_squared_error: 0.6015\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3668 - root_mean_squared_error: 0.6056 - val_loss: 0.3561 - val_root_mean_squared_error: 0.5968\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3654 - root_mean_squared_error: 0.6045 - val_loss: 0.3574 - val_root_mean_squared_error: 0.5978\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3639 - root_mean_squared_error: 0.6032 - val_loss: 0.3507 - val_root_mean_squared_error: 0.5922\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - root_mean_squared_error: 0.6022 - val_loss: 0.3498 - val_root_mean_squared_error: 0.5914\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3626 - root_mean_squared_error: 0.6022\n",
      "Test MSE: 0.36262327432632446\n",
      "Test RMSE: 0.6021820902824402\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 로그 디렉토리 설정\n",
    "run_logdir = get_run_logdir(\"log10\")\n",
    "\n",
    "# Nh=3, Nn=30 모델 구축\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model3.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model3.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])\n",
    "\n",
    "mse_test = model3.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse_test[0])\n",
    "print(\"Test RMSE:\", mse_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.9714 - root_mean_squared_error: 1.4041 - val_loss: 0.8087 - val_root_mean_squared_error: 0.8993\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7355 - root_mean_squared_error: 0.8576 - val_loss: 0.6806 - val_root_mean_squared_error: 0.8250\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6565 - root_mean_squared_error: 0.8102 - val_loss: 0.6319 - val_root_mean_squared_error: 0.7949\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6112 - root_mean_squared_error: 0.7818 - val_loss: 0.5655 - val_root_mean_squared_error: 0.7520\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5746 - root_mean_squared_error: 0.7580 - val_loss: 0.5334 - val_root_mean_squared_error: 0.7303\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5421 - root_mean_squared_error: 0.7363 - val_loss: 0.5023 - val_root_mean_squared_error: 0.7087\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5154 - root_mean_squared_error: 0.7179 - val_loss: 0.4838 - val_root_mean_squared_error: 0.6956\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4928 - root_mean_squared_error: 0.7020 - val_loss: 0.4710 - val_root_mean_squared_error: 0.6863\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4730 - root_mean_squared_error: 0.6878 - val_loss: 0.4394 - val_root_mean_squared_error: 0.6628\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4572 - root_mean_squared_error: 0.6762 - val_loss: 0.4255 - val_root_mean_squared_error: 0.6523\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4448 - root_mean_squared_error: 0.6669 - val_loss: 0.4420 - val_root_mean_squared_error: 0.6649\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4343 - root_mean_squared_error: 0.6590 - val_loss: 0.4106 - val_root_mean_squared_error: 0.6408\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4262 - root_mean_squared_error: 0.6528 - val_loss: 0.4185 - val_root_mean_squared_error: 0.6469\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4193 - root_mean_squared_error: 0.6475 - val_loss: 0.4035 - val_root_mean_squared_error: 0.6352\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4137 - root_mean_squared_error: 0.6432 - val_loss: 0.4208 - val_root_mean_squared_error: 0.6487\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4088 - root_mean_squared_error: 0.6394 - val_loss: 0.3938 - val_root_mean_squared_error: 0.6275\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4047 - root_mean_squared_error: 0.6362 - val_loss: 0.4390 - val_root_mean_squared_error: 0.6626\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4007 - root_mean_squared_error: 0.6330 - val_loss: 0.4037 - val_root_mean_squared_error: 0.6354\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3968 - root_mean_squared_error: 0.6299 - val_loss: 0.3918 - val_root_mean_squared_error: 0.6259\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3940 - root_mean_squared_error: 0.6277 - val_loss: 0.4587 - val_root_mean_squared_error: 0.6773\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3913 - root_mean_squared_error: 0.6255 - val_loss: 0.3980 - val_root_mean_squared_error: 0.6308\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3882 - root_mean_squared_error: 0.6230 - val_loss: 0.4503 - val_root_mean_squared_error: 0.6710\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3859 - root_mean_squared_error: 0.6212 - val_loss: 0.3663 - val_root_mean_squared_error: 0.6052\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3833 - root_mean_squared_error: 0.6191 - val_loss: 0.4127 - val_root_mean_squared_error: 0.6424\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3812 - root_mean_squared_error: 0.6175 - val_loss: 0.4064 - val_root_mean_squared_error: 0.6375\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3790 - root_mean_squared_error: 0.6156 - val_loss: 0.4339 - val_root_mean_squared_error: 0.6587\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3775 - root_mean_squared_error: 0.6144 - val_loss: 0.3580 - val_root_mean_squared_error: 0.5983\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3754 - root_mean_squared_error: 0.6127 - val_loss: 0.4120 - val_root_mean_squared_error: 0.6419\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3740 - root_mean_squared_error: 0.6115 - val_loss: 0.3757 - val_root_mean_squared_error: 0.6130\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3718 - root_mean_squared_error: 0.6097 - val_loss: 0.4264 - val_root_mean_squared_error: 0.6530\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3677 - root_mean_squared_error: 0.6064\n",
      "Test MSE: 0.36774489283561707\n",
      "Test RMSE: 0.6064197421073914\n"
     ]
    }
   ],
   "source": [
    "# Nh=2, Nn=41 모델\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "run_logdir = get_run_logdir(\"log10\")\n",
    "\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(41, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(41, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model2.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model2.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])\n",
    "\n",
    "mse_test = model2.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse_test[0])\n",
    "print(\"Test RMSE:\", mse_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8719 - root_mean_squared_error: 1.3682 - val_loss: 0.9685 - val_root_mean_squared_error: 0.9841\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7270 - root_mean_squared_error: 0.8526 - val_loss: 0.6904 - val_root_mean_squared_error: 0.8309\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6602 - root_mean_squared_error: 0.8125 - val_loss: 0.6333 - val_root_mean_squared_error: 0.7958\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6205 - root_mean_squared_error: 0.7877 - val_loss: 0.5967 - val_root_mean_squared_error: 0.7724\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5875 - root_mean_squared_error: 0.7665 - val_loss: 0.5579 - val_root_mean_squared_error: 0.7469\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5579 - root_mean_squared_error: 0.7469 - val_loss: 0.5173 - val_root_mean_squared_error: 0.7193\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5346 - root_mean_squared_error: 0.7311 - val_loss: 0.5019 - val_root_mean_squared_error: 0.7085\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5145 - root_mean_squared_error: 0.7173 - val_loss: 0.5051 - val_root_mean_squared_error: 0.7107\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4961 - root_mean_squared_error: 0.7044 - val_loss: 0.4578 - val_root_mean_squared_error: 0.6766\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4814 - root_mean_squared_error: 0.6938 - val_loss: 0.4486 - val_root_mean_squared_error: 0.6697\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4695 - root_mean_squared_error: 0.6852 - val_loss: 0.4907 - val_root_mean_squared_error: 0.7005\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4586 - root_mean_squared_error: 0.6772 - val_loss: 0.4347 - val_root_mean_squared_error: 0.6593\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4502 - root_mean_squared_error: 0.6710 - val_loss: 0.4260 - val_root_mean_squared_error: 0.6527\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4423 - root_mean_squared_error: 0.6650 - val_loss: 0.4081 - val_root_mean_squared_error: 0.6388\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4358 - root_mean_squared_error: 0.6601 - val_loss: 0.4117 - val_root_mean_squared_error: 0.6417\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4302 - root_mean_squared_error: 0.6559 - val_loss: 0.3979 - val_root_mean_squared_error: 0.6308\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4254 - root_mean_squared_error: 0.6523 - val_loss: 0.4075 - val_root_mean_squared_error: 0.6383\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4213 - root_mean_squared_error: 0.6491 - val_loss: 0.4072 - val_root_mean_squared_error: 0.6381\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4172 - root_mean_squared_error: 0.6459 - val_loss: 0.3881 - val_root_mean_squared_error: 0.6230\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4140 - root_mean_squared_error: 0.6434 - val_loss: 0.4192 - val_root_mean_squared_error: 0.6474\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4109 - root_mean_squared_error: 0.6410 - val_loss: 0.3887 - val_root_mean_squared_error: 0.6234\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4080 - root_mean_squared_error: 0.6388 - val_loss: 0.4122 - val_root_mean_squared_error: 0.6420\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4055 - root_mean_squared_error: 0.6368 - val_loss: 0.3749 - val_root_mean_squared_error: 0.6123\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4031 - root_mean_squared_error: 0.6349 - val_loss: 0.3928 - val_root_mean_squared_error: 0.6267\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4007 - root_mean_squared_error: 0.6330 - val_loss: 0.4112 - val_root_mean_squared_error: 0.6412\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3990 - root_mean_squared_error: 0.6317 - val_loss: 0.3901 - val_root_mean_squared_error: 0.6246\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3972 - root_mean_squared_error: 0.6302 - val_loss: 0.3675 - val_root_mean_squared_error: 0.6062\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3953 - root_mean_squared_error: 0.6287 - val_loss: 0.3978 - val_root_mean_squared_error: 0.6307\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3938 - root_mean_squared_error: 0.6275 - val_loss: 0.3700 - val_root_mean_squared_error: 0.6083\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3919 - root_mean_squared_error: 0.6260 - val_loss: 0.4034 - val_root_mean_squared_error: 0.6351\n",
      "162/162 [==============================] - 0s 982us/step - loss: 0.3862 - root_mean_squared_error: 0.6214\n",
      "Test MSE: 0.38619670271873474\n",
      "Test RMSE: 0.6214472651481628\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "# number of MAC operation for 1 hidden layers : \n",
    "# 8 x n + n x 1 = 2070 -> n = 230\n",
    "# Nh=1, Nn=230 모델\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "run_logdir = get_run_logdir(\"log10\")\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(230, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model1.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model1.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])\n",
    "\n",
    "mse_test = model1.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse_test[0])\n",
    "print(\"Test RMSE:\", mse_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-87503ac4b2a63898\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-87503ac4b2a63898\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a deep MLP on the MNIST dataset (you can load it using `keras.datasets.mnist.load_data()`. See if you can get over 98% precision. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터셋 로드\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "mnist = keras.datasets.mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for the Fashion MNIST dataset, the MNIST training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)  # 출력: (60000, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is also represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.dtype)  # 출력: uint8 (부호 없는 8비트 정수)\n",
    "print(X_train_full.min(), X_train_full.max())  # 출력: 0 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255, just like we did for Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
    " color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9. Conveniently, the class IDs correspond to the digits represented in the images, so we don't need a `class_names` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# 레이블 확인\n",
    "print(y_train[0])  # 첫 번째 훈련 이미지의 레이블 출력\n",
    "print(y_train[:10])  # 처음 10개 이미지의 레이블 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set contains 5,000 images, and the test set contains 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 세트 크기: (5000, 28, 28) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# 검증 세트 크기 확인\n",
    "print(\"검증 세트 크기:\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 크기: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 크기 확인\n",
    "print(\"테스트 세트 크기:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x480 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple dense network and find the optimal learning rate. We will need a callback to grow the learning rate at each iteration. It will also record the learning rate and the loss at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a small learning rate of 1e-3, and grow it by 0.5% at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model for just 1 epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.5002 - val_loss: nan - val_accuracy: 0.0978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the loss as a functionof the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAG9CAYAAAARC6x6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCmklEQVR4nO3deVyVdf7//+dhXwRckB0Bc99ASRTcyyIry6bFakpr0qkZbWpsmezXZDXfoqaa7NNmu22aLaapZeWeirmXolhugLKjgoAiy/n9QZ5EUUHgXIeLx/12O7db5zrv61yvA1eHp+/r/X5fFqvVahUAAICJORldAAAAQFMj8AAAANMj8AAAANMj8AAAANMj8AAAANMj8AAAANMj8AAAANMj8AAAANMj8AAAANMj8AAAANNzuMCTlJSk/v37y8fHRwEBARozZox27dp1zn1mzpwpi8VS4+Hh4WGnigEAgKNzMbqA061cuVKTJk1S//79VVFRoUcffVSXX365duzYIW9v77Pu5+vrWyMYWSyWOh+zqqpKmZmZ8vHxqdd+AADAOFarVUePHlVISIicnM7dh+NwgWfx4sU1ns+cOVMBAQHatGmThg4detb9LBaLgoKCLuiYmZmZCg8Pv6B9AQCAsTIyMhQWFnbONg4XeE5XWFgoSWrbtu052xUXFysiIkJVVVXq16+fnnnmGfXs2bPWtmVlZSorK7M9P3nD+NcX/qQ/D+nWSJUDwNld/tJKZR45rlkTB6hPWGujywGapaKiIoWHh8vHx+e8bR068FRVVen+++/XoEGD1KtXr7O269q1q9577z316dNHhYWFeuGFF5SQkKCUlJRaE19SUpKefPLJM7Y7e3jJ19e3UT8DANTGxcNbTu5OauXjy/cO0EB1GY7icIOWTzVp0iRt375dn3766TnbxcfHa9y4cYqJidGwYcM0d+5ctW/fXm+++Wat7adOnarCwkLbIyMjQ5JUVl7Z6J8BAAAYz2F7eCZPnqyFCxdq1apV570udzpXV1f17dtXu3fvrvV1d3d3ubu7n7G9rKLqgmoFAACOzeF6eKxWqyZPnqyvvvpKy5YtU1RUVL3fo7KyUtu2bVNwcHC99iuvsNb7WAAAwPE5XA/PpEmTNGvWLM2fP18+Pj7Kzs6WJPn5+cnT01OSNG7cOIWGhiopKUmS9NRTT2ngwIHq1KmTjhw5oueff15paWmaMGFCvY5dVkkPDwAAZuRwgeeNN96QJA0fPrzG9vfff1933HGHJCk9Pb3GfPvDhw9r4sSJys7OVps2bRQbG6u1a9eqR48e9Tp2WQVjeAAAMCOHCzwnp4ify4oVK2o8f+mll/TSSy81+NgnGMMDwE7q8FUHoBE53BgeIxF4ANgba7sD9kHgOQWBBwAAcyLwnIIxPAAAmBOB5xSswwMAgDkReE7BOjwAAJgTgecUXNICAMCcCDynYOFBAADMicBzitSso0aXAAAAmgCB5zS/5hB6AAAwGwLPafbkFhtdAoAWxMLKg4BdEHhOk1V43OgSAABAIyPwnObgkWNGlwAAABoZgec0GYdKjS4BAAA0MgLPaTbsP6QKpqcDAGAqBJ5TeLg66XBpufYX0MsDAICZEHhO0al9K0nSb0xNBwDAVAg8pwht7SmJmVoAAJgNgecU/r7ukqScowQeAE3LauVmxYA9EXhOEezrIYmZWgDsxyJWHgTsgcBziu5BvpKk5D0FKi6rMLgaAADQWAg8p+gRWh14DpeWq9e073S8vNLgigAAQGMg8JzCx8NVIX4etuc7s4oMrAYAADQWAs9pFv1jiO2/d2YxPR0AADMg8Jymjbeb7h7aUZKUkllocDUAAKAxEHhqERvRRpL0/Y4clZ5g8DIAAM0dgacWQ7u0V5Cvh/KOlmnpzlyjywFgQqzCA9gXgacWHq7OuiYmRJK0PJXAA6DpWFiGB7ALAs9ZXNotQFL1Za3cIlZeBgCgOSPwnEX/yLbqFuSj4rIK/b9FO40uBwAANACB5yycnCxK+lNvSdJ3KdksQggAQDNG4DmHmPDWCvHzUFlFlZL3FBhdDgAAuEAEnnOwWCwa8ftYnndX7zO4GgAAcKEIPOcxcUhHOVmk1bvztTu32OhyAADABSDwnEekv7cu+b2XZ/b6dIOrAQAAF4LAUwe3DuggSfpy8wEGLwNoFFZWHgTsisBTB8O6BCi0taeOlJbr2+1ZRpcDAADqicBTB85OFo3tHy5JmvUTl7UAAGhuCDx1NLZ/uJydLNqw/7AyDpUaXQ4AAKgHAk8dBfp6qE+YnyRp+S7urwUAQHNC4KmHq3oHS5I+TE6TlRGHAAA0GwSeehjbP1yers7anVuszemHjS4HAADUEYGnHnw8XHVVn+penk/XZxhcDQAAqCsCTz3d/PtsrYW/ZOno8XKDqwEAAHVB4Kmn2Ig26hzQSsfKK/XFpgNGlwOgmbKKcYCAPRF46slisWh8QqQk6YO1+1VVxZcWgAtnsRhdAdAyEHguwJ/6hcrXw0X7C0qZog4AQDNA4LkAXm4uujmu+v5a76/Zb2wxAADgvAg8F+j2gRFyskird+drd26x0eUAAIBzIPBcoPC2XhrRNUCSGLwMAICDI/A0wI0Xh0mS5m4+oIrKKoOrAQAAZ0PgaYBLugWqrbebco+WadVveUaXAwAAzoLA0wBuLk66rm+oJFZeBgDAkRF4GuiWuOqVl5em5iqn6LjB1QBoLrj/MGBfBJ4G6hTgo/6RbVRZZaWXB0C9WcTKg4A9EHgawW0DIyRJH/+UphMVDF4GAMDREHgawahewQr0dVfe0TIt2pZpdDkAAOA0BJ5G4ObipNt/7+WZzWUtAAAcDoGnkVwfGyaLRVq/75AyDpUaXQ4AADgFgaeRBPt5atBF/pKkeVsOGlwNAAA4FYGnEZ1ck2fuloOyMucUAACHQeBpRFf0CpKnq7P25Zdoa8YRo8sB4MD4JxFgXwSeRuTt7qIregVJkuZu5rIWgPOzsAwPYBcOF3iSkpLUv39/+fj4KCAgQGPGjNGuXbvOu9/nn3+ubt26ycPDQ71799Y333xjh2rP9Kd+1Ze1FvySyZo8AAA4CIcLPCtXrtSkSZO0bt06/fDDDyovL9fll1+ukpKSs+6zdu1a3XLLLbrrrru0ZcsWjRkzRmPGjNH27dvtWHm1hIv8FejrriOl5Vq+K9fuxwcAAGeyWB18dG1eXp4CAgK0cuVKDR06tNY2Y8eOVUlJiRYuXGjbNnDgQMXExGjGjBnnPUZRUZH8/PxUWFgoX1/fBtec9M1OvblqrxJ7BurN2y9u8PsBMJ/+Ty9R3tEyfXvfEHUPbvj3DtAS1efvt8P18JyusLBQktS2bduztklOTtbIkSNrbEtMTFRycnKT1nY2f+oXJklalpqrguIyQ2oAAAB/cOjAU1VVpfvvv1+DBg1Sr169ztouOztbgYGBNbYFBgYqOzu71vZlZWUqKiqq8WhMXYN8FB3mp/JKqz5el96o7w0AAOrPoQPPpEmTtH37dn366aeN+r5JSUny8/OzPcLDwxv1/SXpL4OjJEkzVu5RVuGxRn9/AABQdw4beCZPnqyFCxdq+fLlCgsLO2fboKAg5eTk1NiWk5OjoKCgWttPnTpVhYWFtkdGRuPf/2p0nxDFRrTRsfJKfbA2rdHfHwAA1J3DBR6r1arJkyfrq6++0rJlyxQVFXXefeLj47V06dIa23744QfFx8fX2t7d3V2+vr41Ho3Nycmiu4d2lCR9si5NRcfLG/0YAJovx54uApiPwwWeSZMm6eOPP9asWbPk4+Oj7OxsZWdn69ixPy4LjRs3TlOnTrU9v++++7R48WK9+OKLSk1N1RNPPKGNGzdq8uTJRnwEm5HdA3VRe28dLavQgp8zDa0FgGNi4UHAPhwu8LzxxhsqLCzU8OHDFRwcbHvMmTPH1iY9PV1ZWVm25wkJCZo1a5beeustRUdH64svvtC8efPOOdDZHpycLLq5fwdJ0pwNjX/ZDAAA1I2L0QWcri7LAq1YseKMbTfeeKNuvPHGJqioYa7rF6r/fpeqXw4UamdWEettAABgAIfr4TEb/1buGtm9esr8p+uZog4AgBEIPHZw64Dqy1pzNx9USVmFwdUAANDyEHjsYNBF/oryrx68PG8rd1EHAMDeCDx24ORk0W0DIyRJH65Nq9M4JQAA0HgIPHZyQ2yYvN2ctSvnqJalchd1AADsicBjJ36erraxPLMZvAxA9PQC9kTgsaOb46oDz7LUXKUXlBpcDQBHYBErDwL2QOCxo4vat9KQzv6qskpPLEgxuhwAAFoMAo+d/fvqHpKk5btyuYs6AAB2QuCxsy6BPoqLaiurtXpdHgAA0PQIPAa4MTZMkvTFpgNMUQcAwA4IPAYY1TtYHq5O2pdfopTMIqPLAQDA9Ag8Bmjl7qJLu1XfX+vrnzMNrgYAAPMj8BhkdHSIJGnhz5mqquKyFgAATYnAY5DhXdurlbuLMguPa3P6YaPLAWBnDN8D7IvAYxAPV2dd3rP6stYCLmsBLZaFdQcBuyDwGOia3y9rLdqWpYrKKoOrAQDAvAg8BhrUyV9tvd2UX3xCK3blGV0OAACmReAxkKuzk21NnjdX7WFNHgAAmgiBx2DjEyLl4eqkDfsPa8nOXKPLAQDAlAg8Bgtp7anxCZGSpA/W7je0FgAAzIrA4wBuGxAhi0VavTtfe/KKjS4HAADTIfA4gPC2Xrq0W4Ak6eN1aQZXA8AeGLEH2BeBx0HcNjBCUvUNRUtPVBhcDQB7YRkewD4IPA5iaOf2imznpaPHK7TwlyyjywEAwFQIPA7CycmiP/WrnqL+7TYCDwAAjYnA40Cu7B0kqXrwcuGxcoOrAQDAPAg8DqRTgI+6BLZSeaVVn23IMLocAABMg8DjYCYM6ShJenPVXh07UWlwNQAAmAOBx8Fc1zdUYW08lV9cptnr040uBwAAUyDwOBhXZydNGtFJkjRj5R4dL6eXBwCAhiLwOKDr+4UpxM9DuUfL9OXmA0aXA6AJcLNgwL4IPA7IzcVJd/0+lufdH/epqoovRsCsLKw8CNgFgcdBje0fLh8PF+3NL9EPO3OMLgcAgGaNwOOgWrm76PbfbzcxY+Ueg6sBAKB5I/A4sDsGRcrN2Ulb0o/olwNHjC4HAIBmi8DjwAJ8PDTq99WXP1nHFHUAAC4UgcfB/XlA9WWt+T8f5HYTAABcIAKPg+sf2UZdA310vLxKX25iijoAABeCwOPgLBaLbouv7uX5+Kc01u4AAOACEHiagev6hsrbzVl780qUvKfA6HIANAL+6QLYF4GnGWjl7qLr+oVKkj5al2ZwNQAaFysPAvZA4Gkmbvt9TZ7vd+Qou/C4wdUAANC8EHiaiW5BvoqLbKvKKqs+3cAUdQAA6oPA04z8eWAHSdLs9ekqr6wyuBoAAJoPAk8zckWvIPm3clNOUZmW7OD+WgAA1BWBpxlxd3HW2P7hkqrvr8UUdQAA6obA08zckRAlT1dn/XygUMtSc40uBwCAZoHA08y093HXuN8XInz7x70GVwPgQtFBC9gXgacZGp8QKWcni9btPaSdWUVGlwOgASwswwPYBYGnGQpp7akrelbfRf2DtfuNLQYAgGaAwNNMjU+IlCTN35qpouPcRR0AgHMh8DRT/SPbqEtgKx0rr9TnG7mLOgAA50LgaaYsFoutl2fGyj0qq6g0tiAAABwYgacZuzE2XAE+7so7WqbvUliIEACAsyHwNGNuLk66Oa76dhOvLP2NhQgBADgLAk8zN2FIlFq5u+i33GKt+DXP6HIAAHBIBJ5mztfD1Xa7iXdYiBBoNuiRBeyLwGMCdw6qXohwze4CbT9YaHQ5AOqBdQcB+yDwmEBYGy9d3SdYkvTc4lSDqwEAwPEQeExiymVd5ObspB9/y9faPflGlwMAgEMh8JhERDtv21ied3/cZ3A1AAA4FgKPidw5KFKStDQ1V3vzio0tBgAAB+JwgWfVqlUaPXq0QkJCZLFYNG/evHO2X7FihSwWyxmP7Oxs+xTsQDq2b6VLuwVIkt5ZTS8PAAAnOVzgKSkpUXR0tF577bV67bdr1y5lZWXZHgEBAU1UoWO7a3CUJGn2+nSlZhcZXA0AAI7BxegCTjdq1CiNGjWq3vsFBASodevWjV9QM5PQyV9X9g7SN9uy9cJ3u/TO+P5GlwQAgOEcrofnQsXExCg4OFiXXXaZ1qxZc862ZWVlKioqqvEwkwcv7yoni7RkZ65SMlmXB3BELDsI2FezDzzBwcGaMWOGvvzyS3355ZcKDw/X8OHDtXnz5rPuk5SUJD8/P9sjPDzcjhU3vY7tW+nqPiGSpNdX7DG4GgDnYrGw9CBgD80+8HTt2lV33323YmNjlZCQoPfee08JCQl66aWXzrrP1KlTVVhYaHtkZGTYsWL7+PuIiyRJ32zLYsYWAKDFa/aBpzZxcXHavXv3WV93d3eXr69vjYfZdAvy1cjuAbJapWe/ZfVlAEDLZsrAs3XrVgUHBxtdhuGmXNZVzk4Wfb8jRz9nHDG6HAAADONws7SKi4tr9M7s27dPW7duVdu2bdWhQwdNnTpVBw8e1IcffihJmj59uqKiotSzZ08dP35c77zzjpYtW6bvv//eqI/gMHqE+GpMTKi+3HxAry7frbfHXWx0SQAAGMLhAs/GjRs1YsQI2/MpU6ZIksaPH6+ZM2cqKytL6enpttdPnDihBx54QAcPHpSXl5f69OmjJUuW1HiPluzvIy7S3C0H9MOOHO3MKlL3YPNdvgMA4HwsVqu1xc+OLCoqkp+fnwoLC005nmfSrM1a9EuWru4TrFdv7Wd0OQAk9X7iOx09XqHlDw5XlL+30eUAzVJ9/n6bcgwPapo0vJMkadG2LNblAQC0SASeFqBHiK+u6h0sq1V6/rtdRpcDQGLlQcDOCDwtxEOJ1TO2VuzK08b9h4wuB8DvWHYQsA8CTwsR6e+tG/qFSZKmfZ2iyir+eQkAaDkIPC3IQ1d0lY+Hi1Iyi/TphvTz7wAAgEkQeFoQ/1bu+ufILpKk/1v6m46XVxpcEQAA9kHgaWH+PLCDQlt7KqeoTO+t2Wd0OQAA2AWBp4Vxd3HWA5dX9/K8vnyPco8eN7giAACaHoGnBRoTE6o+YX4qLqvQ9CW/GV0OAABNjsDTAjk5WfTYVT0kSZ9tyFDGoVKDKwJaHuZJAvZF4Gmh4qLaakhnf1VUWenlAQxw8q4+FhbiAeyiQYEnIyNDy5YtU2npHz0EVVVVeu655zRo0CCNHDlSixYtanCRaBoPXt5VkjR3ywGlZhcZXA3QMllYehCwiwYFnn//+9+68cYb5erqatv29NNPa+rUqUpOTtayZcs0ZswYbdiwocGFovFFh7fWlb2DZLVKz36banQ5QIvCJS3AvhoUeNasWaORI0faAo/VatWrr76qbt26KT09XevXr5e3t7eef/75RikWje+hxG5y+f2WE2t25xtdDtBi/H5Fi0tagJ00KPDk5uYqIiLC9nzr1q3Ky8vTvffeq7CwMF188cX08Di4KH9v3Taw+nf4zDc7VcUtJwC7sNLHA9hVgwJPVVWVqqqqbM9XrFghi8WiSy65xLYtNDRU2dnZDTkMmtg/Lu0sH/fqW07M//mg0eUALQI9PIB9NSjwdOjQQevXr7c9nzdvnoKDg9W1a1fbtuzsbLVu3bohh0ETa+vtpr+NuEhS9ViewtJygysCzO9k/46FxAPYRYMCz/XXX681a9bohhtu0G233abVq1fr+uuvr9Fmx44d6tixY4OKRNP7y6AodfT3Vk5RmZ5ckGJ0OYD5nezhMbYKoMVoUOB58MEH1b9/f82dO1ezZs1S79699cQTT9heT0tL0/r16zV8+PAGlomm5uHqrBduipaTRZq75aCW7MgxuiTA1E6O4aGDB7APl4bs7Ovrq3Xr1mn79u2SpO7du8vZ2blGm7lz5+riiy9uyGFgJ/06tNHEoR315sq9enz+dsVf1E7e7g06RQCchW0MD308gF00yl+zXr161bo9IiKixiwuOL77L+2ib7ZlKePQMf13caqevLb23y2AhvljDI+hZQAtRoMuaR09elR79+5VeXnNQa5z5szRn//8Z02YMEFbtmxpUIGwL083Zz1zXW9J0gfJaVq3t8DgigBzst1awuA6gJaiQYHn4YcfVnR0dI3A88Ybb+jWW2/V7Nmz9d5772nw4MFKTWUV3+ZkSOf2uiUuXJL0ry9/UemJCoMrAszHtgoPiQewiwYFnpUrV2rkyJHy8vKybXv22WcVGhqqVatW6bPPPpPVamWl5Wbo0Su7K8TPQ2kFpUr6hsAKNDbG8AD21aDAk5WVpaioKNvznTt3KiMjQ//4xz80ePBg3XDDDbrmmmu0atWqBhcK+/LxcNVzN/SRJH20Lo1ZW0ATYQwPYB8NCjxlZWVyc3OzPV+5cqUsFosuv/xy27aOHTvq4EFW722OhnRur7sGVwfaB7/4WblFxw2uCACAC9OgwBMWFqZffvnF9nzhwoVq27at+vTpY9tWUFCgVq1aNeQwMNC/ruimXqG+OlJaricX7jC6HMAUTg5YlhjCA9hLgwLPqFGj9P333+vBBx/UY489psWLF2v06NE12vz666/q0KFDg4qEcdxcnPTc9X3k7GTRol+ytHQnl7aAhjol73BrCcBOGhR4pk6dqg4dOuh///ufnnnmGQUGBuqpp56yvZ6bm6s1a9Zo6NChDS4UxukZ4me7tPXoV9tUeIx7bQENcep90ok7gH00KPAEBQUpJSVFX3/9tb7++mvt3LlTYWFhttfz8/P1/PPP669//WuDC4WxplzWRVG/32vrmUU7jS4HaNZqXNIi8QB20eCVlj09PXX11VfX+lqPHj3Uo0ePhh4CDsDD1VnPXd9HN72ZrDkbM3RxZBvdeHG40WUBzVLNHh4SD2APjXajpIMHD2rr1q0qKiqSr6+vYmJiFBoa2lhvDwcQF9VWk0d00qvLd2vq3G0K8vPQkM7tjS4LaHasXNMC7K7BgWf37t3629/+pmXLlp3x2qWXXqrXX39dnTp1auhh4CCmXNZFBw6Xat7WTN3/6VZ9e98QBfh6GF0W0KxYxSUtwN4aFHgyMjI0ePBg5ebmqlu3bho6dKiCg4OVnZ2tVatWacmSJRoyZIjWr1+v8HAuf5iBk5NFz17fR7tyirUzq0j3z9mqj+4aIGcnvrWBuqoxS8u4MoAWpUGDlp988knl5ubq9ddfV0pKimbMmKFp06bpjTfeUEpKit544w3l5OTUmLmF5s/D1Vmv3tpXXm7OWrunQDNW7jG6JKDZYlo6YB8NCjzfffedRo8erXvuuafW/2nvvvtujR49Wt9++21DDgMHdFH7Vnrymp6SpP/98KtW/ppncEVA80EPD2B/DQo8ubm56tWr1znb9OrVS3l5/DE0oxtiw/SnvqGqrLJq4gcbWZQQqCPG8AD216DA0759e+3Yce7bDezYsUPt2zOTx4wslurxPIk9A3Wiskp3f7RJczakG10W4PBq9vCQeAB7aFDgSUxM1Ndff61333231tffe+89LViwQFdccUVDDgMH5ubipFdv7adrokNUUWXVI3O36fuUbKPLApoNengA+7BYrTVWhKiX9PR0XXzxxSooKFCPHj00bNgwBQYGKicnR6tWrVJKSoratWunTZs2OfQsraKiIvn5+amwsFC+vr5Gl9MsWa1WPfrVNs1enyFPV2fNuXug+oS1NroswCEVl1Wo17TvJEmp/7lCHq7OBlcENE/1+fvdoGnpHTp00Jo1a3T33XdrxYoVSklJqfH6iBEjNGPGDIcOO2gcFotF/7m2lzKPHNfKX/P0l5kb9dXfExTe1svo0gCH04B/ZwK4QA26pCVJnTt31rJly5SWlqb58+fro48+0vz585WWlqalS5dq7ty5uvTSSxujVjg4F2cnvXprX3UL8lF+cZnunb1F5ZVVRpcFOJwaCy1zSQuwi0a7tUR4eHitPTmpqalasWJFYx0GDs7Hw1Xv3tFfo6av0taMI3p8foqeua4Xa40Ap2DQMmB/De7hAU4X2tpT02+OkZNFmr0+Xe+u3md0SYBjOTXwkHcAuyDwoElc0i1Qj17ZXZL09Dc7WaMHOEWNdXgMrANoSQg8aDJ3DY7SLXEdZLVK/5i9RVszjhhdEuAQalzSoosHsAsCD5qMxWLRU9f2VMJF7VRyolK3vfOTdmUfNboswHA1Bi0bVgXQshB40KRcnZ30xm2xio1oo+KyCt31wQblF5cZXRZgqFOnpdPBA9hHvWdpXXnllfVqv23btvoeAibj5+mqd8ZdrDGvr1FaQanu/miTPpkwgMXW0GLVnJZO4gHsod6BZ/HixfU+CP9Do423m94d31/Xvb5Gm9IO675Pt+iVW/rJzYVORrQ8rDsI2F+9A8++fUwxxoXpFNBKb91+sca/t17fpeRo4ocb9cZt/eTl1mjLQQHNwslZWvxbELCfev+liYiIaIo60ELEX9ROb42L1d8+3qyVv+bp9nfX673x/eXn5Wp0aYD9/N7DQ94B7IfrCbC74V0D9PGEAfL1cNGmtMMa+1ayco8eN7oswO643A/YD4EHhoiNaKPP7olXex93pWYf1Y0zkpVxqNTosgC7YAgPYH8EHhimW5CvvrwnQeFtPZVWUKobZqzVnrxio8sCmpyVS1qA3RF4YKgO7bz0xT0J6hLYSjlFZbppRrJW/ppndFlAk2LQMmB/BB4YLtDXQ7MnDlTPEF8VlJzQ+PfW65lvdqqqio5/mNMfPTwkHsBeCDxwCO1aueuzu+M1Lr56FuBbq/bqno83qeh4ucGVAY3PFuXJO4DdEHjgMLzdXfTUtb300thouTpb9P2OHI17d70KSwk9MJeTt5Yg7wD2Q+CBw7mub5g+/etAtfZy1daMI7rpzWRlFR4zuiyg0dguaZF4ALsh8MAhxUa01ad/HahAX3ftyjmq619fq99yuNM6zIUxPID9EHjgsLoF+erLvyWoY3tvZRYe1zWvrtG327KMLgtoMHp4APtzuMCzatUqjR49WiEhIbJYLJo3b95591mxYoX69esnd3d3derUSTNnzmzyOmEfYW2qp60nXNROx8or9fdZm/Xeau7nhubNNi3d4DqAlsThAk9JSYmio6P12muv1an9vn37dNVVV2nEiBHaunWr7r//fk2YMEHfffddE1cKe2nr7aaP7hqg2wdGyGqVnlq4Q/9ZuEOVTFtHM/VHDw+RB7AXh7tN9ahRozRq1Kg6t58xY4aioqL04osvSpK6d++u1atX66WXXlJiYmJTlQk7c3ay6Klreyq0jaee/TZV767epz15xXr55r7y8+TGo2heTkZ14g5gPw7Xw1NfycnJGjlyZI1tiYmJSk5OPus+ZWVlKioqqvGA47NYLLpn2EX6v1v6ysPVSSt25enaV1drVzaDmdG8WLm3BGB3zT7wZGdnKzAwsMa2wMBAFRUV6dix2qcyJyUlyc/Pz/YIDw+3R6loJNdEh+iLexIU2tpT+wtKdd3ra/QNg5kBAOfQ7APPhZg6daoKCwttj4yMDKNLQj31CvXTgnsHa1Cndio9Uam/f7JZ/12cyrgeNAtc0gLsr9kHnqCgIOXk5NTYlpOTI19fX3l6eta6j7u7u3x9fWs80Py09XbTB3fGaeKQKEnS6yv26C8zN7AyMxweg5YB+2v2gSc+Pl5Lly6tse2HH35QfHy8QRXBnlycnfT/XdVDL98cIw9XJ638NU9jXl+jjEOlRpcGnAN3SwfszeECT3FxsbZu3aqtW7dKqp52vnXrVqWnp0uqvhw1btw4W/t77rlHe/fu1cMPP6zU1FS9/vrr+uyzz/TPf/7TiPJhkGtjQvXl36rH9ezLL9GNM5K1Of2w0WUBtWLMMmB/Dhd4Nm7cqL59+6pv376SpClTpqhv3756/PHHJUlZWVm28CNJUVFRWrRokX744QdFR0frxRdf1DvvvMOU9BaoZ4ifvvxbgjoHtFJ20XHdOCNZ05f8qorKKqNLA2qwjeGhiwewG4vVNj+y5SoqKpKfn58KCwsZz2MChcfK9fj87Zq/NVOS1CfMT9PHxqhj+1YGVwZU25V9VInTV6mdt5s2/fsyo8sBmq36/P12uB4eoKH8PF318s19NX1sjHw9XPTLgUJd/cpqfbHpgMj3cARWxvAAdkfggWmN6Ruq7/85TPEdq6euP/j5z7r17Z+0/WCh0aWhhfsjd5N4AHsh8MDUgvw89PGEAXrw8i5ydbYoeW+Brn1tjaZ8tlVpBSVGl4cWirulA/ZH4IHpOTtZNPmSzlrx0Ahd2TtIlVVWzd18UJe+uFIv/fArixXC7rhbOmB/BB60GKGtPfX6n2M1a8IADe3SXhVVVr289Ddd/cpqfZ+SbXR5aEHo4QHsj8CDFiehk78+/Eucpo+NkY+7i3ZmFemvH23SlDlbWbAQdmWhjwewGwIPWqwxfUP1479G6J5hF8nJIs3dclBD/rtcV/3fj1q+K5cZXWhy9PAA9kPgQYvW2stNj4zqps/viVfCRe3k7GRRSmaR7nx/g257lxldaBpkacD+CDyApNiItpo1caA2/n8j9dehHeXm7KQ1uwt09Sur9c85W3XgMJe60HgYtAzYH4EHOEUbbzc9emV3LX1gmK6NCZEkfbXloC55caWSvtmpwmPciR0Nx93SAfsj8AC1CG/rpZdv7qsFkwcrvmM7naio0pur9mr488s1Z0O6qpjKjgbg7AHsj8ADnEPvMD/NmjhA79/RX50DWulwabn+9eU2/emNtYzvwQU7OSCeDh7Afgg8wHlYLBaN6Bagb+4boseu6q5W7i7amnFEo19drYe/+Fm7c4uNLhHNzB93Sze0DKBFcTG6AKC5cHV20oQhHTU6OkTPfLNT87dm6rONB/Tl5oO66eIw9Qlrre7BvooO82NsBs7JNoaHYcuA3RB4gHoK9PXQyzf31S1xHTRj5R6t2JWn2eszNHt9hiSpQ1svXdc3VDf1D1doa0+Dq4Vj4pIWYG8EHuACDezYTgM7ttOG/Yf08bo0HSkt1/p9h5R+qFQvL/1NM1bu0b2XdNL4hEj5eLgaXS4cyB89PADshcADNFD/yLbqH9lWklR6okLfp+Tok5/StGH/Yb3w/a96Y8UeXRMToj8PiFCvUD+Dq4Uj+GMMD5EHsBcGLQONyMvNRWP6huqzu+M1fWyMOrb3VsmJSs1en6GrX1mt29/9SWv35HPbihauorL69+/sROAB7IUeHqAJWCwWjekbqmtjQvTjb/n6YtMBLdqWpR9/y9ePv+WrY3tvxYS31nV9Q5VwkT9/+FqYiqoqSdUD4QHYB4EHaEIWi0VDu7TX0C7t9VBiV721aq++2HRAe/NKtDevRHM3H1SXwFZ64PKuGtE1QG4u/AFsCcorTwYegi5gLwQewE7C23rpP2N66aErumrJjhxtTDusBT9n6tecYt390SZ5ujrrsh6Buq5vqAZ39udf/yZW/vslLRd69gC7IfAAdubr4ao/9QvTn/qF6V+J3fTGyj36fGOGCkpO6OufM/X1z5ny9XDRn/qF6Y6ESEX6extdMhrZHz08hFrAXgg8gIH8vFz1yKhu+tcVXfXzgULN23JQC3/JVH7xCc1cu18fJO9XwkXtNLhTe8Vf1I5FDU3i5KBlAg9gPwQewAFYLBbFhLdWTHhr/fvqHlqzO1/vr9mn5bvytGZ3gdbsLpAk9Qzx1R0JkRodHSIPV2eDq8aFOsEYHsDuCDyAg3F2+mOgc1pBiZbszNWGfYe0fFeuUjKL9NAXv+j/LdqpK3sHa3SfYA3o2I5ZXs3MyR4eF3p4ALsh8AAOLKKdt+4aHKW7BkfpcMkJzdmYoY+S03TwyDHNXp+u2evT1d7HXVf1DtbVfYLVr0MbORF+HN4f09L5XQH2QuABmok23m66Z9hFmjiko9btLdDXWzO1OCVbeUfLNHPtfs1cu18hfh66OjpEV/cJVu9Qxvs4qhMVDFoG7I3AAzQzzk4WDerkr0Gd/PWfMb20Zne+Fvycqe935Ciz8LjeWrVXb63aq4h2XhrdJ0Sjo0PUNcjH6LJxioqqk9PSCTyAvRB4gGbMzcVJI7oFaES3AB0vr9SKXXla8Eumlu7MUVpBqV5dvluvLt+t8LaeSujor4RO7RTZzls9QnzpXTBQ+e89PG4u9MAB9kLgAUzCw9VZV/QK0hW9glRSVqGlqbla8HOmVu7KU8ahY5pzKENzNmZIkjxdnXV1n2DdMqCDeob4yt2FGV/2VE4PD2B3BB7AhLzdXXRNdIiuiQ5R0fFyJe8p0PLUXP2ac1R78kpUeKxcn286oM83HZCzk0Xdg30U5d9KcZFtNKiTv6L8vRn/08isVqsOl5Zrd26xPv89eLby4CsYsBeLlds2q6ioSH5+fiosLJSvr6/R5QBNqqrKqs3ph/VBcppW7spV0fGKM9oE+3ko4SJ/DerUTgM7tlNIa08DKm2eCo+Va8O+Q9qw/5C2ZxbqREWVTlRadfDwMeUXl9nauTk76bt/DlUUK2kDF6w+f78JPCLwoOWyWq3al1+i7ZlF2p9forV78rU57YhtYbyTovy9NbRz9UDpoV3at/hFD4+XV2rVr3nal19i25ZddFwZh0q16tf8M35+p/LxcNGwLu01YUhHxYS3tkO1gHkReOqJwAP84diJSm1MO6TVu/OVvKdAKZlFqqz642vC09VZUf7e6tuhtTq2b6WBHduqe5Bvi1j/p6yiUq8s3a23f9yrsoqzh5rIdl4aENVO/SJay9fDVS7OTmrj5apeoX4tPiwCjYnAU08EHuDsjh4v19o9BfrxtzwtT83TwSPHzmjT3sddiT0DdWNsuKJN2mtRXlml699Yq18OFEqS/Fu5KzaitbzdXWS1Sn6ergpr46n4i9qpZ4ifwdUCLQOBp54IPEDdWK1W7c4t1q85xfppX4H25pVoc/phlZ6otLWJ8vfW4E7+CvLzUDtvN8VGtNHh0nLtyCxUu1buau/jrsh23gry8zDwk9RP3tEy3f7uT0rNPipXZ4v+7+a+uqJXEAO7AYMReOqJwANcuLKKSiXvKdD8rZla9EvWOcevnCqsjaf6dWgjF2eL8otPKKyNp7oEtFKXQB91CfKRfyt3SdUhy8hgUV5ZpTveX681uwvk4+Gip6/rrWuiQwyrB8AfCDz1ROABGkfR8XKt21OgH3/LV1bhcZWeqNDGtMOqqrKqb4fWssiivOIypRWUqOo83zw+Hi46dqJSbi5Oio1oo/Y+7nJ1clJUe2/169BGYW085efpKm/3ppvaXVFZpcmztmhxSrY8XJ20YPJgdQ5k1WrAUdTn7zeLQJyi9ESFXE6cOUUXQN24OFk0uLO/Bnf2t20rq6iU1aoag3WLyyr0c8YRpWQWqaLSKldnJxWXlWt3bol25x1VxqFjOvr7dPmKE5X68bf8sx4zpLWHBka1VVzHtops10ruLk7y8XCVk0XamnFE/q2qL6G1a+Uqi8Viu4+Vm0vNRf9Kyir0UXKadmQVqbisQn5erjp46Ji2ZxZJkv4zppdC23iqlO8IwGHU5/9Henj0R0IMv/8zObl7GV0OAACog6qyUmVMv6lOPTysaw4AAEyPHh790cOTlVfAGB7ABMorq1RWUaVWv4/vKauo1IHDx3W45ITat3KXl5uzCo+Xq6D4hApKylRQfEK+ni5K7BnEOjlAM1JUVKTg9u0Yw1NfXm4u8nLjRwKYjZebi9p4uRtdBoBGVlGPv9lc0gIAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKZH4AEAAKbnsIHntddeU2RkpDw8PDRgwACtX7/+rG1nzpwpi8VS4+Hh4WHHagEAgCNzyMAzZ84cTZkyRdOmTdPmzZsVHR2txMRE5ebmnnUfX19fZWVl2R5paWl2rBgAADgyhww8//vf/zRx4kTdeeed6tGjh2bMmCEvLy+99957Z93HYrEoKCjI9ggMDLRjxQAAwJE5XOA5ceKENm3apJEjR9q2OTk5aeTIkUpOTj7rfsXFxYqIiFB4eLiuvfZapaSk2KNcAADQDDhc4MnPz1dlZeUZPTSBgYHKzs6udZ+uXbvqvffe0/z58/Xxxx+rqqpKCQkJOnDgQK3ty8rKVFRUVOMBAADMy+ECz4WIj4/XuHHjFBMTo2HDhmnu3Llq37693nzzzVrbJyUlyc/Pz/YIDw+3c8UAAMCeHC7w+Pv7y9nZWTk5OTW25+TkKCgoqE7v4erqqr59+2r37t21vj516lQVFhbaHhkZGQ2uGwAAOC6HCzxubm6KjY3V0qVLbduqqqq0dOlSxcfH1+k9KisrtW3bNgUHB9f6uru7u3x9fWs8AACAebkYXUBtpkyZovHjx+viiy9WXFycpk+frpKSEt15552SpHHjxik0NFRJSUmSpKeeekoDBw5Up06ddOTIET3//PNKS0vThAkTjPwYAADAQThk4Bk7dqzy8vL0+OOPKzs7WzExMVq8eLFtIHN6erqcnP7onDp8+LAmTpyo7OxstWnTRrGxsVq7dq169Ohh1EcAAAAOxGK1Wq1GF2G0oqIi+fn5qbCwkMtbAAA0E/X5++1wY3gAAAAaG4EHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYHoEHAACYnsMGntdee02RkZHy8PDQgAEDtH79+nO2//zzz9WtWzd5eHiod+/e+uabb+xUKQAAcHQOGXjmzJmjKVOmaNq0adq8ebOio6OVmJio3NzcWtuvXbtWt9xyi+666y5t2bJFY8aM0ZgxY7R9+3Y7Vw4AAByRxWq1Wo0u4nQDBgxQ//799eqrr0qSqqqqFB4ernvvvVePPPLIGe3Hjh2rkpISLVy40LZt4MCBiomJ0YwZM857vKKiIvn5+amwsFC+vr6N90EAAECTqc/fbxc71VRnJ06c0KZNmzR16lTbNicnJ40cOVLJycm17pOcnKwpU6bU2JaYmKh58+bV2r6srExlZWW254WFhZKqf3AAAKB5OPl3uy59Nw4XePLz81VZWanAwMAa2wMDA5WamlrrPtnZ2bW2z87OrrV9UlKSnnzyyTO2h4eHX2DVAADAKEePHpWfn9852zhc4LGHqVOn1ugROnLkiCIiIpSenn7eH5hR+vfvrw0bNjj0+9f3PerTvi5tz9fmbK+fbXtRUZHCw8OVkZHhsJc6m/K8MOKcqM8+TXlOnO01zgnHPifq0pZzwvHevyHnhNVq1dGjRxUSEnLefRwu8Pj7+8vZ2Vk5OTk1tufk5CgoKKjWfYKCgurV3t3dXe7u7mds9/Pzc9gT1tnZuUlra4z3r+971Kd9Xdqer83ZXj/ffr6+vi3yvDDinKjPPk15TpzvNc4J+75HY35XcE443vs39Jyoa0eFw83ScnNzU2xsrJYuXWrbVlVVpaVLlyo+Pr7WfeLj42u0l6QffvjhrO2bo0mTJjn8+9f3PerTvi5tz9fmbK839c+2KTVl7UacE/XZpynPifrU4Wha8jlRl7acE473/k19TpzkkLO05syZo/Hjx+vNN99UXFycpk+frs8++0ypqakKDAzUuHHjFBoaqqSkJEnV09KHDRumZ599VldddZU+/fRTPfPMM9q8ebN69ep13uMxSwu14bzA6TgncDrOiebD4S5pSdXTzPPy8vT4448rOztbMTExWrx4sW1gcnp6upyc/uicSkhI0KxZs/TYY4/p0UcfVefOnTVv3rw6hR2p+hLXtGnTar3MhZaL8wKn45zA6Tgnmg+H7OEBAABoTA43hgcAAKCxEXgAAIDpEXgAAIDpEXgAAIDpEXgAAIDpEXjqKSMjQ8OHD1ePHj3Up08fff7550aXBAdw3XXXqU2bNrrhhhuMLgUGWbhwobp27arOnTvrnXfeMbocOAi+GxwH09LrKSsrSzk5OYqJiVF2drZiY2P166+/ytvb2+jSYKAVK1bo6NGj+uCDD/TFF18YXQ7srKKiQj169NDy5cvl5+en2NhYrV27Vu3atTO6NBiM7wbHQQ9PPQUHBysmJkZS9T28/P39dejQIWOLguGGDx8uHx8fo8uAQdavX6+ePXsqNDRUrVq10qhRo/T9998bXRYcAN8NjsN0gWfVqlUaPXq0QkJCZLFYNG/evDPavPbaa4qMjJSHh4cGDBig9evXX9CxNm3apMrKSoWHhzewajQle54TaJ4aeo5kZmYqNDTU9jw0NFQHDx60R+loQnx3mIvpAk9JSYmio6P12muv1fr6nDlzNGXKFE2bNk2bN29WdHS0EhMTlZuba2sTExOjXr16nfHIzMy0tTl06JDGjRunt956q8k/ExrGXucEmq/GOEdgPpwXJmM1MUnWr776qsa2uLg466RJk2zPKysrrSEhIdakpKQ6v+/x48etQ4YMsX744YeNVSrspKnOCavVal2+fLn1+uuvb4wyYaALOUfWrFljHTNmjO31++67z/rJJ5/YpV7YR0O+O/hucAym6+E5lxMnTmjTpk0aOXKkbZuTk5NGjhyp5OTkOr2H1WrVHXfcoUsuuUS33357U5UKO2mMcwLmVpdzJC4uTtu3b9fBgwdVXFysb7/9VomJiUaVDDvgu6P5aVGBJz8/X5WVlba7rp8UGBio7OzsOr3HmjVrNGfOHM2bN08xMTGKiYnRtm3bmqJc2EFjnBOSNHLkSN1444365ptvFBYWxheeidTlHHFxcdGLL76oESNGKCYmRg888AAztEyurt8dfDc4DhejC2huBg8erKqqKqPLgINZsmSJ0SXAYNdcc42uueYao8uAg+G7wXG0qB4ef39/OTs7Kycnp8b2nJwcBQUFGVQVjMQ5gfPhHEFtOC+anxYVeNzc3BQbG6ulS5fatlVVVWnp0qWKj483sDIYhXMC58M5gtpwXjQ/prukVVxcrN27d9ue79u3T1u3blXbtm3VoUMHTZkyRePHj9fFF1+suLg4TZ8+XSUlJbrzzjsNrBpNiXMC58M5gtpwXpiM0dPEGtvy5cutks54jB8/3tbmlVdesXbo0MHq5uZmjYuLs65bt864gtHkOCdwPpwjqA3nhblwLy0AAGB6LWoMDwAAaJkIPAAAwPQIPAAAwPQIPAAAwPQIPAAAwPQIPAAAwPQIPAAAwPQIPAAAwPQIPACateHDh8tisRhdBgAHR+ABWoD9+/fLYrHoiiuuMLoU1NMTTzwhi8WiFStWGF0K0KyZ7uahAFqWDz/8UKWlpUaXAcDBEXgANGsdOnQwugQAzQCXtACc4ejRo5o2bZp69uwpT09PtW7dWomJiVq9evUZbTdt2qTJkyerV69e8vPzk6enp3r37q1nn31W5eXlZ7SPjIxUZGSkjhw5osmTJys8PFwuLi6aOXOm7dLbHXfcod27d+u6665TmzZt5O3trZEjR+rnn38+4/1qG8Mzc+ZMWSwWzZw5U99//70SEhLk5eWldu3aafz48SooKKj1c7/55pvq2bOnPDw8FB4erocffljHjx+XxWLR8OHD6/SzO/US1MyZM9WvXz95eXnZ9i8sLNRzzz2nYcOGKSQkRG5ubgoJCdG4ceO0Z8+eMz7bk08+KUkaMWKELBaLLBaLIiMja7TLzc3VP//5T3Xq1Enu7u7y9/fX9ddfr+3bt9epZqAloIcHQA2HDh3S0KFDlZKSokGDBumee+5RUVGR5s+frxEjRujzzz/XmDFjbO3ffvttLViwQEOHDtWVV16p0tJSrVixQlOnTtWGDRv05ZdfnnGMsrIyXXLJJSouLtY111wjFxcXBQYG2l7fv3+/Bg4cqJ49e+ovf/mL9uzZYzv+zp07a7Q9l6+//lqLFi3S6NGjlZCQoFWrVunDDz/Unj17zghvjz/+uP7zn/8oMDBQEydOlKurqz777DOlpqZe0M/x+eef1/Lly3Xttdfq8ssvl7OzsyRp586devzxxzVixAhdd9118vb2VmpqqmbNmqVFixZp8+bNioiIkCTdcccdkqSVK1dq/PjxtqDTunVr23H27Nmj4cOH68CBA7r88ss1ZswY5ebm6ssvv9R3332npUuXasCAARf0GQBTsQIwvX379lklWRMTE8/b9tZbb7VKsr799ts1tufk5FjDw8Ot7du3tx47dsy2PS0tzVpRUVGjbVVVlfUvf/mLVZJ19erVNV6LiIiw1VJaWlprnZKszz77bI3XHnvsMaska1JSUo3tw4YNs57+Vfb+++9bJVldXFxqHL+iosI6fPhwqyRrcnKybfuuXbuszs7O1tDQUGtOTo5te1FRkbVHjx5WSdZhw4ad7UdWw7Rp06ySrN7e3tZffvnljNePHDliLSgoOGP7smXLrE5OTtYJEybU+n7Lly+v9XgJCQlWZ2dn6+LFi2ts37Vrl9XHx8fau3fvOtUNmB2XtADY5Ofna86cObrkkks0YcKEGq8FBATooYceUl5enpYsWWLb3qFDB1vvxUkWi0WTJk2SpBptT/Xf//5Xnp6etb4WFRWlhx56qMa2u+66S5K0YcOGOn+eW2+9VYMGDbI9d3Z21vjx4894n9mzZ6uyslIPPPCAAgICbNt9fHz02GOP1fl4p/rrX/+q3r17n7Hdz89Pbdu2PWP7iBEj1LNnz7P+vGqzZcsWrV27VuPHj1diYmKN17p06aKJEydq27ZtXNoCxCUtAKfYsGGDKisrVVZWpieeeOKM13/77TdJUmpqqq6++mpJ0okTJ/Tqq6/q008/VWpqqoqLi2W1Wm37ZGZmnvE+Hh4etYaBk2JiYuTkVPPfY2FhYZKkI0eO1PnzxMbGnrGttvc5OTZo8ODBZ7Q/NTDVR1xc3FlfW7FihaZPn66ffvpJ+fn5qqiosL3m5uZW52OsW7dOkpSTk1Pr7+vk5bjU1FT16tWrzu8LmBGBB4DNoUOHJElr1qzRmjVrztqupKTE9t833HCDFixYoC5dumjs2LEKCAiQq6urjhw5opdfflllZWVn7B8QEHDOxQJ9fX3P2ObiUv11VVlZWefPU9f3KSoqstV1urqOF6rrfp9//rnGjh2rVq1aKTExUZGRkfLy8rINsk5LS6vzMU7+vhYtWqRFixadtd2pvy+gpSLwALA5GRAeeOABvfDCC+dtv2HDBi1YsECJiYlatGhRjUtb69at08svv1zrfo62MvLJz52bm2sbMHxSTk7OBb3n2T7jE088IQ8PD23atEmdO3eu8dqnn35ar2OcrPuVV17R5MmTL6hOoKVgDA8Am/79+8tisSg5OblO7U9Oo77qqqvOGMfz448/Nnp9TSU6OlqSau3VWrt2baMea8+ePerevfsZYScrK0t79+49o/3Jn2ttPVsnZ1/V9fcFtGQEHgA2QUFBuummm7R27Vo9//zzNcbinPTTTz/ZVjY+2Rty+hTvlJQUJSUlNX3BjeTmm2+Wk5OTXnzxReXn59u2l5SU6Omnn27UY0VERGj37t01eo6OHz+uv/3tb7WuW3RygHNGRsYZr8XFxWnAgAGaPXu25syZc8brVVVVWrlyZSNWDzRfXNICWpBt27bZ1nY5Xbdu3fTII4/o9ddf165du/Twww/ro48+Unx8vFq3bq2MjAxt3LhRv/32m7KysuTl5aW4uDjFxcXps88+U1ZWlgYOHKj09HR9/fXXuuqqq/TFF1/Y9wNeoK5du+qRRx7RM888o969e+umm26Si4uL5s6dq969e2v79u1nDKK+UPfee6/uvfde9e3bVzfccIMqKir0ww8/yGq1Kjo6+ozFFU8uOPjoo48qJSVFfn5+at26te0S1uzZszVixAjdfPPNmj59uvr16ydPT0+lp6crOTlZeXl5On78eKPUDjRnBB6gBcnMzNQHH3xQ62vDhg3TI488orZt22rt2rV69dVXNWfOHH3yySeqqqpSUFCQoqOj9e9//1v+/v6Sqi+3LFy4UI888ogWL16sDRs2qHPnznrhhRc0atSoZhN4JOnpp59WWFiYXnnlFc2YMUMBAQG6+eabdd9992nBggW1DoC+EJMmTZKrq6teeeUVvf3222rdurWuuuoqJSUl6cYbbzyjfY8ePfT+++/rxRdf1CuvvKKysjJFRETYAk9UVJS2bNmi//3vf5o3b57ef/99OTs7Kzg4WEOHDtUNN9zQKHUDzZ3FWlufNQBAUvU6QpdddpkefvhhPffcc0aXA+ACMYYHACTl5eWdMTD4yJEjmjp1qiTVuJ0GgOaHS1oAIOmTTz7RCy+8oEsuuUQhISHKysrS4sWLlZubqzvuuEPx8fFGlwigAQg8ACApISFBsbGxWrJkiQ4dOiRnZ2d1795d//73v/X3v//d6PIANBBjeAAAgOkxhgcAAJgegQcAAJgegQcAAJgegQcAAJgegQcAAJgegQcAAJgegQcAAJgegQcAAJgegQcAAJje/w8vhuIqQwCj7gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss starts shooting back up violently around 3e-1, so let's try using 2e-1 as our learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=2e-1)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_mnist_logs\\\\run_001'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0787 - val_accuracy: 0.9830\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0792 - val_accuracy: 0.9834\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0819 - val_accuracy: 0.9850\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0795 - val_accuracy: 0.9846\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0805 - val_accuracy: 0.9862\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 3.5533e-04 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9868\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 2.4801e-04 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9864\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 2.0372e-04 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9860\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.7953e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9864\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.6049e-04 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9866\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.4528e-04 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9868\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.3295e-04 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9866\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.2321e-04 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9864\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.1549e-04 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9864\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.0837e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9864\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.0213e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9864\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 9.6421e-05 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9864\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 9.1212e-05 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9866\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.7276e-05 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9866\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.2830e-05 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb, checkpoint_cb, tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06863506138324738, 0.9825000166893005]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\")\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got over 98% accuracy. Finally, let's look at the learning curves using TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b5899b87c4249\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b5899b87c4249\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch-CUDA)",
   "language": "python",
   "name": "py39cuda118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
